{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c2bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"purchase100\"\n",
    "algorithm = \"crown ibp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0665ea7",
   "metadata": {},
   "source": [
    "### 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e937f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from art.utils import to_categorical\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "with open(\"data/dataset_purchase\", \"r\") as f:\n",
    "    for datapoint in f.readlines(): \n",
    "        split = datapoint.rstrip().split(\",\")\n",
    "        label = int(split[0]) - 1\n",
    "        x.append([int(s) for s in split[1:]])\n",
    "        y.append(label)\n",
    "\n",
    "x = np.array(x).astype(np.float32)\n",
    "y = to_categorical(np.array(y), 100)\n",
    "\n",
    "target_train_size = 10000\n",
    "target_test_size = 10000\n",
    "x_target_train = x[:target_train_size]\n",
    "y_target_train = y[:target_train_size]\n",
    "x_target_test = x[target_train_size:target_train_size+target_test_size]\n",
    "y_target_test = y[target_train_size:target_train_size+target_test_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa1313",
   "metadata": {},
   "source": [
    "### 2. Define Target Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df7910fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]          76,928\n",
      "              ReLU-2                  [-1, 128]               0\n",
      "            Linear-3                  [-1, 100]          12,900\n",
      "================================================================\n",
      "Total params: 89,828\n",
      "Trainable params: 89,828\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.34\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import math\n",
    "\n",
    "def purchase_model(): \n",
    "    model = nn.Sequential(            \n",
    "        nn.Linear(600, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 100)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "summary(purchase_model(), input_size=x_target_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db6326",
   "metadata": {},
   "source": [
    "### 3. Train Target Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8126fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:29:32     Namespace(batch_size=64, bound_opts=None, bound_type='CROWN-IBP', clip_grad_norm=8.0, data='p100', device='cpu', eps=0.03137254901960784, load='', lr=0.0005, lr_decay_milestones=[70, 85], lr_decay_rate=0.1, model='purchase_model', no_loss_fusion=False, norm=2, num_epochs=100, scheduler_name='SmoothedScheduler', scheduler_opts='start=10,length=61,mid=0.4', seed=100, verify=False)\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "INFO     10:29:48     macs: 179200.0, params: 89828.0\n",
      "INFO     10:29:48     Sequential(\n",
      "  (0): Linear(in_features=600, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=100, bias=True)\n",
      ")\n",
      "INFO     10:29:48     Epoch 1, learning rate [0.0005]\n",
      "INFO     10:29:49     [ 1:  50]: eps=0.000000000000 CE=3.7057 grad_norm=1.0519 Loss=3.7057 Time=0.0011\n",
      "INFO     10:29:49     [ 1: 100]: eps=0.000000000000 CE=3.5302 grad_norm=1.2211 Loss=3.5302 Time=0.0011\n",
      "INFO     10:29:49     [ 1: 150]: eps=0.000000000000 CE=3.3715 grad_norm=1.3869 Loss=3.3715 Time=0.0010\n",
      "INFO     10:29:49     [ 1: 157]: eps=0.000000000000 CE=3.3570 grad_norm=1.4226 Loss=3.3570 Time=0.0010\n",
      "INFO     10:29:49     Epoch time: 1.7461, Total time: 1.7461\n",
      "INFO     10:29:49     Evaluating...\n",
      "INFO     10:29:51     [ 1: 157]: eps=0.000000000000 CE=3.4779 Err=0.7929 Loss=3.4779 Time=0.0011\n",
      "INFO     10:29:51     Epoch 2, learning rate [0.0005]\n",
      "INFO     10:29:52     [ 2:  50]: eps=0.000000000000 CE=2.6661 grad_norm=2.1052 Loss=2.6661 Time=0.0012\n",
      "INFO     10:29:52     [ 2: 100]: eps=0.000000000000 CE=2.5194 grad_norm=2.2722 Loss=2.5194 Time=0.0011\n",
      "INFO     10:29:52     [ 2: 150]: eps=0.000000000000 CE=2.3649 grad_norm=2.4077 Loss=2.3649 Time=0.0022\n",
      "INFO     10:29:52     [ 2: 157]: eps=0.000000000000 CE=2.3490 grad_norm=2.4391 Loss=2.3490 Time=0.0022\n",
      "INFO     10:29:52     Epoch time: 1.5885, Total time: 3.3346\n",
      "INFO     10:29:52     Evaluating...\n",
      "INFO     10:29:54     [ 2: 157]: eps=0.000000000000 CE=2.2737 Err=0.5626 Loss=2.2737 Time=0.0011\n",
      "INFO     10:29:54     Epoch 3, learning rate [0.0005]\n",
      "INFO     10:29:55     [ 3:  50]: eps=0.000000000000 CE=1.7819 grad_norm=2.8743 Loss=1.7819 Time=0.0012\n",
      "INFO     10:29:55     [ 3: 100]: eps=0.000000000000 CE=1.6807 grad_norm=2.9288 Loss=1.6807 Time=0.0012\n",
      "INFO     10:29:55     [ 3: 150]: eps=0.000000000000 CE=1.5962 grad_norm=2.9984 Loss=1.5962 Time=0.0011\n",
      "INFO     10:29:55     [ 3: 157]: eps=0.000000000000 CE=1.5866 grad_norm=3.0201 Loss=1.5866 Time=0.0011\n",
      "INFO     10:29:55     Epoch time: 1.3804, Total time: 4.7149\n",
      "INFO     10:29:55     Evaluating...\n",
      "INFO     10:29:56     [ 3: 157]: eps=0.000000000000 CE=1.6372 Err=0.4121 Loss=1.6372 Time=0.0011\n",
      "INFO     10:29:56     Epoch 4, learning rate [0.0005]\n",
      "INFO     10:29:57     [ 4:  50]: eps=0.000000000000 CE=1.2624 grad_norm=3.1237 Loss=1.2624 Time=0.0012\n",
      "INFO     10:29:57     [ 4: 100]: eps=0.000000000000 CE=1.2104 grad_norm=3.1312 Loss=1.2104 Time=0.0012\n",
      "INFO     10:29:58     [ 4: 150]: eps=0.000000000000 CE=1.1684 grad_norm=3.2028 Loss=1.1684 Time=0.0012\n",
      "INFO     10:29:58     [ 4: 157]: eps=0.000000000000 CE=1.1628 grad_norm=3.2350 Loss=1.1628 Time=0.0012\n",
      "INFO     10:29:58     Epoch time: 1.3398, Total time: 6.0547\n",
      "INFO     10:29:58     Evaluating...\n",
      "INFO     10:29:59     [ 4: 157]: eps=0.000000000000 CE=1.3197 Err=0.3463 Loss=1.3197 Time=0.0011\n",
      "INFO     10:29:59     Epoch 5, learning rate [0.0005]\n",
      "INFO     10:30:00     [ 5:  50]: eps=0.000000000000 CE=0.9701 grad_norm=3.1771 Loss=0.9701 Time=0.0012\n",
      "INFO     10:30:00     [ 5: 100]: eps=0.000000000000 CE=0.9319 grad_norm=3.1744 Loss=0.9319 Time=0.0011\n",
      "INFO     10:30:00     [ 5: 150]: eps=0.000000000000 CE=0.9085 grad_norm=3.2180 Loss=0.9085 Time=0.0011\n",
      "INFO     10:30:00     [ 5: 157]: eps=0.000000000000 CE=0.9067 grad_norm=3.2598 Loss=0.9067 Time=0.0011\n",
      "INFO     10:30:00     Epoch time: 1.3537, Total time: 7.4085\n",
      "INFO     10:30:00     Evaluating...\n",
      "INFO     10:30:02     [ 5: 157]: eps=0.000000000000 CE=1.1236 Err=0.3049 Loss=1.1236 Time=0.0012\n",
      "INFO     10:30:02     Epoch 6, learning rate [0.0005]\n",
      "INFO     10:30:03     [ 6:  50]: eps=0.000000000000 CE=0.7752 grad_norm=3.1811 Loss=0.7752 Time=0.0012\n",
      "INFO     10:30:03     [ 6: 100]: eps=0.000000000000 CE=0.7650 grad_norm=3.2241 Loss=0.7650 Time=0.0011\n",
      "INFO     10:30:03     [ 6: 150]: eps=0.000000000000 CE=0.7468 grad_norm=3.2420 Loss=0.7468 Time=0.0011\n",
      "INFO     10:30:03     [ 6: 157]: eps=0.000000000000 CE=0.7452 grad_norm=3.2590 Loss=0.7452 Time=0.0011\n",
      "INFO     10:30:03     Epoch time: 1.3842, Total time: 8.7927\n",
      "INFO     10:30:03     Evaluating...\n",
      "INFO     10:30:05     [ 6: 157]: eps=0.000000000000 CE=0.9926 Err=0.2768 Loss=0.9926 Time=0.0012\n",
      "INFO     10:30:05     Epoch 7, learning rate [0.0005]\n",
      "INFO     10:30:06     [ 7:  50]: eps=0.000000000000 CE=0.6534 grad_norm=3.1998 Loss=0.6534 Time=0.0011\n",
      "INFO     10:30:06     [ 7: 100]: eps=0.000000000000 CE=0.6415 grad_norm=3.1634 Loss=0.6415 Time=0.0011\n",
      "INFO     10:30:06     [ 7: 150]: eps=0.000000000000 CE=0.6326 grad_norm=3.1741 Loss=0.6326 Time=0.0011\n",
      "INFO     10:30:06     [ 7: 157]: eps=0.000000000000 CE=0.6332 grad_norm=3.2042 Loss=0.6332 Time=0.0011\n",
      "INFO     10:30:06     Epoch time: 1.3475, Total time: 10.1402\n",
      "INFO     10:30:06     Evaluating...\n",
      "INFO     10:30:07     [ 7: 157]: eps=0.000000000000 CE=0.9264 Err=0.2704 Loss=0.9264 Time=0.0010\n",
      "INFO     10:30:07     Epoch 8, learning rate [0.0005]\n",
      "INFO     10:30:08     [ 8:  50]: eps=0.000000000000 CE=0.5696 grad_norm=3.0780 Loss=0.5696 Time=0.0012\n",
      "INFO     10:30:08     [ 8: 100]: eps=0.000000000000 CE=0.5573 grad_norm=3.1276 Loss=0.5573 Time=0.0011\n",
      "INFO     10:30:08     [ 8: 150]: eps=0.000000000000 CE=0.5480 grad_norm=3.1344 Loss=0.5480 Time=0.0011\n",
      "INFO     10:30:09     [ 8: 157]: eps=0.000000000000 CE=0.5474 grad_norm=3.1442 Loss=0.5474 Time=0.0011\n",
      "INFO     10:30:09     Epoch time: 1.3531, Total time: 11.4933\n",
      "INFO     10:30:09     Evaluating...\n",
      "INFO     10:30:10     [ 8: 157]: eps=0.000000000000 CE=0.8627 Err=0.2606 Loss=0.8627 Time=0.0011\n",
      "INFO     10:30:10     Epoch 9, learning rate [0.0005]\n",
      "INFO     10:30:11     [ 9:  50]: eps=0.000000000000 CE=0.4952 grad_norm=3.0168 Loss=0.4952 Time=0.0012\n",
      "INFO     10:30:11     [ 9: 100]: eps=0.000000000000 CE=0.4894 grad_norm=3.0356 Loss=0.4894 Time=0.0011\n",
      "INFO     10:30:11     [ 9: 150]: eps=0.000000000000 CE=0.4832 grad_norm=3.0074 Loss=0.4832 Time=0.0011\n",
      "INFO     10:30:11     [ 9: 157]: eps=0.000000000000 CE=0.4832 grad_norm=3.0331 Loss=0.4832 Time=0.0011\n",
      "INFO     10:30:11     Epoch time: 1.3475, Total time: 12.8408\n",
      "INFO     10:30:11     Evaluating...\n",
      "INFO     10:30:13     [ 9: 157]: eps=0.000000000000 CE=0.8178 Err=0.2564 Loss=0.8178 Time=0.0011\n",
      "INFO     10:30:13     Epoch 10, learning rate [0.0005]\n",
      "INFO     10:30:14     [10:  50]: eps=0.000000000120 CE=0.0104 grad_norm=2.8447 Loss=0.4633 Time=0.0119 Robust_CE=0.4621\n",
      "INFO     10:30:15     [10: 100]: eps=0.000000002000 CE=0.0052 grad_norm=2.8412 Loss=0.4625 Time=0.0117 Robust_CE=0.4619\n",
      "INFO     10:30:15     [10: 150]: eps=0.000000010263 CE=0.0035 grad_norm=2.8866 Loss=0.4659 Time=0.0116 Robust_CE=0.4656\n",
      "INFO     10:30:16     [10: 157]: eps=0.000000012332 CE=0.0033 grad_norm=2.9040 Loss=0.4661 Time=0.0116 Robust_CE=0.4658\n",
      "INFO     10:30:16     Epoch time: 3.0245, Total time: 15.8653\n",
      "INFO     10:30:16     Evaluating...\n",
      "INFO     10:30:17     [10: 157]: eps=0.000000012332 CE=0.7882 Err=0.2508 Loss=0.7882 Robust_CE=0.7882 Verified_Err=0.2508 Time=0.0029\n",
      "INFO     10:30:17     Epoch 11, learning rate [0.0005]\n",
      "INFO     10:30:19     [11:  50]: eps=0.000000037497 CE=0.0000 grad_norm=2.8469 Loss=0.4172 Robust_CE=0.4172 Time=0.0117\n",
      "INFO     10:30:20     [11: 100]: eps=0.000000089431 CE=0.0000 grad_norm=2.7923 Loss=0.4159 Robust_CE=0.4159 Time=0.0116\n",
      "INFO     10:30:20     [11: 150]: eps=0.000000182563 CE=0.0000 grad_norm=2.8054 Loss=0.4134 Robust_CE=0.4134 Time=0.0116\n",
      "INFO     10:30:20     [11: 157]: eps=0.000000199850 CE=0.0000 grad_norm=2.8239 Loss=0.4132 Robust_CE=0.4132 Time=0.0116\n",
      "INFO     10:30:20     Epoch time: 3.0055, Total time: 18.8708\n",
      "INFO     10:30:20     Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:30:22     [11: 157]: eps=0.000000199850 CE=0.7500 Err=0.2484 Loss=0.7500 Robust_CE=0.7500 Verified_Err=0.2484 Time=0.0031\n",
      "INFO     10:30:22     Epoch 12, learning rate [0.0005]\n",
      "INFO     10:30:24     [12:  50]: eps=0.000000361538 CE=0.0000 grad_norm=2.7112 Loss=0.3787 Robust_CE=0.3787 Time=0.0118\n",
      "INFO     10:30:24     [12: 100]: eps=0.000000605797 CE=0.0000 grad_norm=2.6609 Loss=0.3689 Robust_CE=0.3689 Time=0.0118\n",
      "INFO     10:30:25     [12: 150]: eps=0.000000956866 CE=0.0000 grad_norm=2.7055 Loss=0.3688 Robust_CE=0.3688 Time=0.0118\n",
      "INFO     10:30:25     [12: 157]: eps=0.000001016058 CE=0.0000 grad_norm=2.7074 Loss=0.3674 Robust_CE=0.3674 Time=0.0117\n",
      "INFO     10:30:25     Epoch time: 3.0807, Total time: 21.9515\n",
      "INFO     10:30:25     Evaluating...\n",
      "INFO     10:30:27     [12: 157]: eps=0.000001016058 CE=0.7328 Err=0.2454 Loss=0.7329 Robust_CE=0.7329 Verified_Err=0.2454 Time=0.0030\n",
      "INFO     10:30:27     Epoch 13, learning rate [0.0005]\n",
      "INFO     10:30:29     [13:  50]: eps=0.000001522441 CE=0.0000 grad_norm=2.5262 Loss=0.3294 Robust_CE=0.3294 Time=0.0118\n",
      "INFO     10:30:29     [13: 100]: eps=0.000002197994 CE=0.0000 grad_norm=2.5359 Loss=0.3262 Robust_CE=0.3262 Time=0.0117\n",
      "INFO     10:30:30     [13: 150]: eps=0.000003076762 CE=0.0000 grad_norm=2.5614 Loss=0.3256 Robust_CE=0.3256 Time=0.0117\n",
      "INFO     10:30:30     [13: 157]: eps=0.000003218083 CE=0.0000 grad_norm=2.5764 Loss=0.3250 Robust_CE=0.3250 Time=0.0117\n",
      "INFO     10:30:30     Epoch time: 3.0496, Total time: 25.0011\n",
      "INFO     10:30:30     Evaluating...\n",
      "INFO     10:30:32     [13: 157]: eps=0.000003218083 CE=0.7000 Err=0.2335 Loss=0.7001 Robust_CE=0.7001 Verified_Err=0.2335 Time=0.0030\n",
      "INFO     10:30:32     Epoch 14, learning rate [0.0005]\n",
      "INFO     10:30:33     [14:  50]: eps=0.000004374030 CE=0.0000 grad_norm=2.2975 Loss=0.2894 Robust_CE=0.2894 Time=0.0119\n",
      "INFO     10:30:34     [14: 100]: eps=0.000005816540 CE=0.0000 grad_norm=2.3836 Loss=0.2883 Robust_CE=0.2883 Time=0.0118\n",
      "INFO     10:30:34     [14: 150]: eps=0.000007589465 CE=0.0000 grad_norm=2.4932 Loss=0.2933 Robust_CE=0.2933 Time=0.0118\n",
      "INFO     10:30:35     [14: 157]: eps=0.000007866678 CE=0.0000 grad_norm=2.5086 Loss=0.2926 Robust_CE=0.2926 Time=0.0118\n",
      "INFO     10:30:35     Epoch time: 3.0712, Total time: 28.0723\n",
      "INFO     10:30:35     Evaluating...\n",
      "INFO     10:30:36     [14: 157]: eps=0.000007866678 CE=0.7124 Err=0.2478 Loss=0.7125 Robust_CE=0.7125 Verified_Err=0.2478 Time=0.0030\n",
      "INFO     10:30:36     Epoch 15, learning rate [0.0005]\n",
      "INFO     10:30:38     [15:  50]: eps=0.000010073753 CE=0.0000 grad_norm=2.3615 Loss=0.2612 Robust_CE=0.2612 Time=0.0118\n",
      "INFO     10:30:39     [15: 100]: eps=0.000012715580 CE=0.0000 grad_norm=2.3698 Loss=0.2604 Robust_CE=0.2604 Time=0.0118\n",
      "INFO     10:30:39     [15: 150]: eps=0.000015845816 CE=0.0000 grad_norm=2.3834 Loss=0.2626 Robust_CE=0.2626 Time=0.0118\n",
      "INFO     10:30:40     [15: 157]: eps=0.000016326218 CE=0.0000 grad_norm=2.4034 Loss=0.2637 Robust_CE=0.2637 Time=0.0118\n",
      "INFO     10:30:40     Epoch time: 3.0816, Total time: 31.1539\n",
      "INFO     10:30:40     Evaluating...\n",
      "INFO     10:30:41     [15: 157]: eps=0.000016326218 CE=0.6970 Err=0.2458 Loss=0.6971 Robust_CE=0.6971 Verified_Err=0.2459 Time=0.0030\n",
      "INFO     10:30:41     Epoch 16, learning rate [0.0005]\n",
      "INFO     10:30:43     [16:  50]: eps=0.000020082682 CE=0.0000 grad_norm=2.2523 Loss=0.2411 Robust_CE=0.2411 Time=0.0120\n",
      "INFO     10:30:43     [16: 100]: eps=0.000024452880 CE=0.0000 grad_norm=2.2102 Loss=0.2386 Robust_CE=0.2386 Time=0.0118\n",
      "INFO     10:30:44     [16: 150]: eps=0.000029500277 CE=0.0000 grad_norm=2.2310 Loss=0.2365 Robust_CE=0.2365 Time=0.0118\n",
      "INFO     10:30:44     [16: 157]: eps=0.000030264706 CE=0.0000 grad_norm=2.2422 Loss=0.2355 Robust_CE=0.2355 Time=0.0118\n",
      "INFO     10:30:44     Epoch time: 3.1371, Total time: 34.2910\n",
      "INFO     10:30:44     Evaluating...\n",
      "INFO     10:30:46     [16: 157]: eps=0.000030264706 CE=0.6923 Err=0.2465 Loss=0.6926 Robust_CE=0.6926 Verified_Err=0.2466 Time=0.0030\n",
      "INFO     10:30:46     Epoch 17, learning rate [0.0005]\n",
      "INFO     10:30:48     [17:  50]: eps=0.000036165515 CE=0.0000 grad_norm=2.0569 Loss=0.2080 Robust_CE=0.2080 Time=0.0119\n",
      "INFO     10:30:48     [17: 100]: eps=0.000042889835 CE=0.0000 grad_norm=2.0499 Loss=0.2103 Robust_CE=0.2103 Time=0.0121\n",
      "INFO     10:30:49     [17: 150]: eps=0.000050510939 CE=0.0000 grad_norm=2.1010 Loss=0.2113 Robust_CE=0.2113 Time=0.0119\n",
      "INFO     10:30:49     [17: 157]: eps=0.000051653767 CE=0.0000 grad_norm=2.1137 Loss=0.2112 Robust_CE=0.2112 Time=0.0119\n",
      "INFO     10:30:49     Epoch time: 3.1198, Total time: 37.4108\n",
      "INFO     10:30:49     Evaluating...\n",
      "INFO     10:30:51     [17: 157]: eps=0.000051653767 CE=0.6660 Err=0.2359 Loss=0.6666 Robust_CE=0.6666 Verified_Err=0.2361 Time=0.0030\n",
      "INFO     10:30:51     Epoch 18, learning rate [0.0005]\n",
      "INFO     10:30:53     [18:  50]: eps=0.000060390572 CE=0.0000 grad_norm=1.9321 Loss=0.1888 Robust_CE=0.1888 Time=0.0132\n",
      "INFO     10:30:53     [18: 100]: eps=0.000070191461 CE=0.0000 grad_norm=1.9840 Loss=0.1901 Robust_CE=0.1901 Time=0.0125\n",
      "INFO     10:30:54     [18: 150]: eps=0.000081139513 CE=0.0000 grad_norm=2.0271 Loss=0.1917 Robust_CE=0.1917 Time=0.0122\n",
      "INFO     10:30:54     [18: 157]: eps=0.000082768653 CE=0.0000 grad_norm=2.0288 Loss=0.1919 Robust_CE=0.1919 Time=0.0121\n",
      "INFO     10:30:54     Epoch time: 3.3984, Total time: 40.8092\n",
      "INFO     10:30:54     Evaluating...\n",
      "INFO     10:30:56     [18: 157]: eps=0.000082768653 CE=0.6595 Err=0.2380 Loss=0.6604 Robust_CE=0.6604 Verified_Err=0.2386 Time=0.0030\n",
      "INFO     10:30:56     Epoch 19, learning rate [0.0005]\n",
      "INFO     10:30:58     [19:  50]: eps=0.000095129801 CE=0.0000 grad_norm=1.9272 Loss=0.1752 Robust_CE=0.1752 Time=0.0119\n",
      "INFO     10:30:58     [19: 100]: eps=0.000108826400 CE=0.0000 grad_norm=1.9357 Loss=0.1738 Robust_CE=0.1738 Time=0.0118\n",
      "INFO     10:30:59     [19: 150]: eps=0.000123951337 CE=0.0000 grad_norm=1.9485 Loss=0.1739 Robust_CE=0.1739 Time=0.0117\n",
      "INFO     10:30:59     [19: 157]: eps=0.000126188237 CE=0.0000 grad_norm=1.9528 Loss=0.1737 Robust_CE=0.1737 Time=0.0117\n",
      "INFO     10:30:59     Epoch time: 3.1318, Total time: 43.9411\n",
      "INFO     10:30:59     Evaluating...\n",
      "INFO     10:31:01     [19: 157]: eps=0.000126188237 CE=0.6583 Err=0.2385 Loss=0.6597 Robust_CE=0.6597 Verified_Err=0.2392 Time=0.0030\n",
      "INFO     10:31:01     Epoch 20, learning rate [0.0005]\n",
      "INFO     10:31:03     [20:  50]: eps=0.000143058772 CE=0.0000 grad_norm=1.6646 Loss=0.1497 Robust_CE=0.1497 Time=0.0118\n",
      "INFO     10:31:03     [20: 100]: eps=0.000161566920 CE=0.0000 grad_norm=1.7550 Loss=0.1516 Robust_CE=0.1516 Time=0.0117\n",
      "INFO     10:31:04     [20: 150]: eps=0.000181815375 CE=0.0000 grad_norm=1.8325 Loss=0.1565 Robust_CE=0.1565 Time=0.0117\n",
      "INFO     10:31:04     [20: 157]: eps=0.000184795020 CE=0.0000 grad_norm=1.8446 Loss=0.1567 Robust_CE=0.1567 Time=0.0117\n",
      "INFO     10:31:04     Epoch time: 3.1147, Total time: 47.0558\n",
      "INFO     10:31:04     Evaluating...\n",
      "INFO     10:31:06     [20: 157]: eps=0.000184795020 CE=0.6462 Err=0.2372 Loss=0.6482 Robust_CE=0.6482 Verified_Err=0.2384 Time=0.0030\n",
      "INFO     10:31:06     Epoch 21, learning rate [0.0005]\n",
      "INFO     10:31:08     [21:  50]: eps=0.000207156681 CE=0.0000 grad_norm=1.7044 Loss=0.1405 Robust_CE=0.1405 Time=0.0118\n",
      "INFO     10:31:08     [21: 100]: eps=0.000231488911 CE=0.0000 grad_norm=1.6546 Loss=0.1398 Robust_CE=0.1398 Time=0.0118\n",
      "INFO     10:31:09     [21: 150]: eps=0.000257904212 CE=0.0000 grad_norm=1.6747 Loss=0.1410 Robust_CE=0.1410 Time=0.0117\n",
      "INFO     10:31:09     [21: 157]: eps=0.000261775127 CE=0.0000 grad_norm=1.6865 Loss=0.1412 Robust_CE=0.1412 Time=0.0117\n",
      "INFO     10:31:09     Epoch time: 3.1354, Total time: 50.1912\n",
      "INFO     10:31:09     Evaluating...\n",
      "INFO     10:31:11     [21: 157]: eps=0.000261775127 CE=0.6549 Err=0.2426 Loss=0.6579 Robust_CE=0.6579 Verified_Err=0.2440 Time=0.0030\n",
      "INFO     10:31:11     Epoch 22, learning rate [0.0005]\n",
      "INFO     10:31:12     [22:  50]: eps=0.000290706347 CE=0.0000 grad_norm=1.6138 Loss=0.1262 Robust_CE=0.1262 Time=0.0119\n",
      "INFO     10:31:13     [22: 100]: eps=0.000321971889 CE=0.0000 grad_norm=1.6136 Loss=0.1283 Robust_CE=0.1283 Time=0.0118\n",
      "INFO     10:31:14     [22: 150]: eps=0.000355694060 CE=0.0000 grad_norm=1.6198 Loss=0.1282 Robust_CE=0.1282 Time=0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:31:14     [22: 157]: eps=0.000360618305 CE=0.0000 grad_norm=1.6344 Loss=0.1284 Robust_CE=0.1284 Time=0.0117\n",
      "INFO     10:31:14     Epoch time: 3.1355, Total time: 53.3268\n",
      "INFO     10:31:14     Evaluating...\n",
      "INFO     10:31:16     [22: 157]: eps=0.000360618305 CE=0.6469 Err=0.2410 Loss=0.6510 Robust_CE=0.6510 Verified_Err=0.2426 Time=0.0030\n",
      "INFO     10:31:16     Epoch 23, learning rate [0.0005]\n",
      "INFO     10:31:17     [23:  50]: eps=0.000397294216 CE=0.0000 grad_norm=1.4817 Loss=0.1160 Robust_CE=0.1160 Time=0.0122\n",
      "INFO     10:31:18     [23: 100]: eps=0.000436698994 CE=0.0000 grad_norm=1.4708 Loss=0.1152 Robust_CE=0.1152 Time=0.0119\n",
      "INFO     10:31:19     [23: 150]: eps=0.000478964756 CE=0.0000 grad_norm=1.5021 Loss=0.1165 Robust_CE=0.1165 Time=0.0120\n",
      "INFO     10:31:19     [23: 157]: eps=0.000485117929 CE=0.0000 grad_norm=1.5113 Loss=0.1164 Robust_CE=0.1164 Time=0.0119\n",
      "INFO     10:31:19     Epoch time: 3.1892, Total time: 56.5160\n",
      "INFO     10:31:19     Evaluating...\n",
      "INFO     10:31:21     [23: 157]: eps=0.000485117929 CE=0.6457 Err=0.2367 Loss=0.6513 Robust_CE=0.6513 Verified_Err=0.2387 Time=0.0030\n",
      "INFO     10:31:21     Epoch 24, learning rate [0.0005]\n",
      "INFO     10:31:22     [24:  50]: eps=0.000530810357 CE=0.0000 grad_norm=1.4356 Loss=0.1079 Robust_CE=0.1079 Time=0.0119\n",
      "INFO     10:31:23     [24: 100]: eps=0.000579656992 CE=0.0000 grad_norm=1.4001 Loss=0.1044 Robust_CE=0.1044 Time=0.0118\n",
      "INFO     10:31:23     [24: 150]: eps=0.000631799760 CE=0.0000 grad_norm=1.4028 Loss=0.1054 Robust_CE=0.1054 Time=0.0118\n",
      "INFO     10:31:24     [24: 157]: eps=0.000639370997 CE=0.0000 grad_norm=1.4171 Loss=0.1054 Robust_CE=0.1054 Time=0.0117\n",
      "INFO     10:31:24     Epoch time: 3.1408, Total time: 59.6568\n",
      "INFO     10:31:24     Evaluating...\n",
      "INFO     10:31:26     [24: 157]: eps=0.000639370997 CE=0.6398 Err=0.2381 Loss=0.6474 Robust_CE=0.6474 Verified_Err=0.2408 Time=0.0030\n",
      "INFO     10:31:26     Epoch 25, learning rate [0.0005]\n",
      "INFO     10:31:27     [25:  50]: eps=0.000695448463 CE=0.0000 grad_norm=1.3460 Loss=0.0953 Robust_CE=0.0953 Time=0.0119\n",
      "INFO     10:31:28     [25: 100]: eps=0.000755136272 CE=0.0000 grad_norm=1.3463 Loss=0.0954 Robust_CE=0.0954 Time=0.0118\n",
      "INFO     10:31:28     [25: 150]: eps=0.000818586158 CE=0.0000 grad_norm=1.3583 Loss=0.0963 Robust_CE=0.0963 Time=0.0119\n",
      "INFO     10:31:29     [25: 157]: eps=0.000827778132 CE=0.0000 grad_norm=1.3811 Loss=0.0967 Robust_CE=0.0967 Time=0.0118\n",
      "INFO     10:31:29     Epoch time: 3.1585, Total time: 62.8153\n",
      "INFO     10:31:29     Evaluating...\n",
      "INFO     10:31:31     [25: 157]: eps=0.000827778132 CE=0.6437 Err=0.2397 Loss=0.6537 Robust_CE=0.6537 Verified_Err=0.2436 Time=0.0030\n",
      "INFO     10:31:31     Epoch 26, learning rate [0.0005]\n",
      "INFO     10:31:32     [26:  50]: eps=0.000895705853 CE=0.0000 grad_norm=1.3228 Loss=0.0900 Robust_CE=0.0900 Time=0.0120\n",
      "INFO     10:31:33     [26: 100]: eps=0.000967730849 CE=0.0000 grad_norm=1.2645 Loss=0.0882 Robust_CE=0.0882 Time=0.0119\n",
      "INFO     10:31:33     [26: 150]: eps=0.001044014658 CE=0.0000 grad_norm=1.2554 Loss=0.0875 Robust_CE=0.0875 Time=0.0119\n",
      "INFO     10:31:34     [26: 157]: eps=0.001055043580 CE=0.0000 grad_norm=1.2714 Loss=0.0875 Robust_CE=0.0875 Time=0.0119\n",
      "INFO     10:31:34     Epoch time: 3.1765, Total time: 65.9919\n",
      "INFO     10:31:34     Evaluating...\n",
      "INFO     10:31:35     [26: 157]: eps=0.001055043580 CE=0.6476 Err=0.2374 Loss=0.6606 Robust_CE=0.6606 Verified_Err=0.2419 Time=0.0030\n",
      "INFO     10:31:35     Epoch 27, learning rate [0.0005]\n",
      "INFO     10:31:37     [27:  50]: eps=0.001136383470 CE=0.0000 grad_norm=1.2067 Loss=0.0817 Robust_CE=0.0817 Time=0.0122\n",
      "INFO     10:31:38     [27: 100]: eps=0.001222338360 CE=0.0000 grad_norm=1.1951 Loss=0.0810 Robust_CE=0.0810 Time=0.0120\n",
      "INFO     10:31:38     [27: 150]: eps=0.001313079597 CE=0.0000 grad_norm=1.1809 Loss=0.0803 Robust_CE=0.0803 Time=0.0119\n",
      "INFO     10:31:39     [27: 157]: eps=0.001326175214 CE=0.0000 grad_norm=1.1846 Loss=0.0803 Robust_CE=0.0803 Time=0.0118\n",
      "INFO     10:31:39     Epoch time: 3.1704, Total time: 69.1623\n",
      "INFO     10:31:39     Evaluating...\n",
      "INFO     10:31:41     [27: 157]: eps=0.001326175214 CE=0.6449 Err=0.2414 Loss=0.6616 Robust_CE=0.6616 Verified_Err=0.2483 Time=0.0032\n",
      "INFO     10:31:41     Epoch 28, learning rate [0.0005]\n",
      "INFO     10:31:43     [28:  50]: eps=0.001422585882 CE=0.0000 grad_norm=1.0333 Loss=0.0712 Robust_CE=0.0712 Time=0.0128\n",
      "INFO     10:31:43     [28: 100]: eps=0.001524160070 CE=0.0000 grad_norm=1.0799 Loss=0.0726 Robust_CE=0.0726 Time=0.0125\n",
      "INFO     10:31:44     [28: 150]: eps=0.001631078933 CE=0.0000 grad_norm=1.0947 Loss=0.0729 Robust_CE=0.0729 Time=0.0123\n",
      "INFO     10:31:44     [28: 157]: eps=0.001646484531 CE=0.0000 grad_norm=1.1094 Loss=0.0730 Robust_CE=0.0730 Time=0.0123\n",
      "INFO     10:31:44     Epoch time: 3.4858, Total time: 72.6481\n",
      "INFO     10:31:44     Evaluating...\n",
      "INFO     10:31:46     [28: 157]: eps=0.001646484531 CE=0.6529 Err=0.2446 Loss=0.6740 Robust_CE=0.6740 Verified_Err=0.2527 Time=0.0033\n",
      "INFO     10:31:46     Epoch 29, learning rate [0.0005]\n",
      "INFO     10:31:48     [29:  50]: eps=0.001759721281 CE=0.0000 grad_norm=1.0140 Loss=0.0657 Robust_CE=0.0657 Time=0.0133\n",
      "INFO     10:31:49     [29: 100]: eps=0.001878700867 CE=0.0000 grad_norm=1.0295 Loss=0.0665 Robust_CE=0.0665 Time=0.0130\n",
      "INFO     10:31:50     [29: 150]: eps=0.002003614250 CE=0.0000 grad_norm=1.0341 Loss=0.0665 Robust_CE=0.0665 Time=0.0129\n",
      "INFO     10:31:50     [29: 157]: eps=0.002021586650 CE=0.0000 grad_norm=1.0441 Loss=0.0667 Robust_CE=0.0667 Time=0.0129\n",
      "INFO     10:31:50     Epoch time: 3.7534, Total time: 76.4016\n",
      "INFO     10:31:50     Evaluating...\n",
      "INFO     10:31:52     [29: 157]: eps=0.002021586650 CE=0.6482 Err=0.2419 Loss=0.6745 Robust_CE=0.6745 Verified_Err=0.2514 Time=0.0029\n",
      "INFO     10:31:52     Epoch 30, learning rate [0.0005]\n",
      "INFO     10:31:54     [30:  50]: eps=0.002153501483 CE=0.0000 grad_norm=0.9138 Loss=0.0608 Robust_CE=0.0608 Time=0.0130\n",
      "INFO     10:31:55     [30: 100]: eps=0.002291769262 CE=0.0000 grad_norm=0.9162 Loss=0.0607 Robust_CE=0.0607 Time=0.0130\n",
      "INFO     10:31:55     [30: 150]: eps=0.002436590755 CE=0.0000 grad_norm=0.9259 Loss=0.0607 Robust_CE=0.0607 Time=0.0129\n",
      "INFO     10:31:56     [30: 157]: eps=0.002457400319 CE=0.0000 grad_norm=0.9263 Loss=0.0605 Robust_CE=0.0605 Time=0.0129\n",
      "INFO     10:31:56     Epoch time: 3.6255, Total time: 80.0271\n",
      "INFO     10:31:56     Evaluating...\n",
      "INFO     10:31:58     [30: 157]: eps=0.002457400319 CE=0.6571 Err=0.2445 Loss=0.6900 Robust_CE=0.6900 Verified_Err=0.2591 Time=0.0036\n",
      "INFO     10:31:58     Epoch 31, learning rate [0.0005]\n",
      "INFO     10:32:00     [31:  50]: eps=0.002609941931 CE=0.0000 grad_norm=0.8872 Loss=0.0560 Robust_CE=0.0560 Time=0.0142\n",
      "INFO     10:32:01     [31: 100]: eps=0.002769477394 CE=0.0000 grad_norm=0.8888 Loss=0.0560 Robust_CE=0.0560 Time=0.0152\n",
      "INFO     10:32:01     [31: 150]: eps=0.002936217283 CE=0.0000 grad_norm=0.8834 Loss=0.0560 Robust_CE=0.0560 Time=0.0140\n",
      "INFO     10:32:02     [31: 157]: eps=0.002960147907 CE=0.0000 grad_norm=0.8962 Loss=0.0561 Robust_CE=0.0561 Time=0.0139\n",
      "INFO     10:32:02     Epoch time: 3.8822, Total time: 83.9093\n",
      "INFO     10:32:02     Evaluating...\n",
      "INFO     10:32:04     [31: 157]: eps=0.002960147907 CE=0.6524 Err=0.2421 Loss=0.6925 Robust_CE=0.6925 Verified_Err=0.2566 Time=0.0030\n",
      "INFO     10:32:04     Epoch 32, learning rate [0.0005]\n",
      "INFO     10:32:06     [32:  50]: eps=0.003135361690 CE=0.0000 grad_norm=0.8334 Loss=0.0503 Robust_CE=0.0503 Time=0.0121\n",
      "INFO     10:32:06     [32: 100]: eps=0.003318241023 CE=0.0000 grad_norm=0.8221 Loss=0.0511 Robust_CE=0.0511 Time=0.0119\n",
      "INFO     10:32:07     [32: 150]: eps=0.003509006290 CE=0.0000 grad_norm=0.8267 Loss=0.0512 Robust_CE=0.0512 Time=0.0118\n",
      "INFO     10:32:07     [32: 157]: eps=0.003536355409 CE=0.0000 grad_norm=0.8294 Loss=0.0513 Robust_CE=0.0513 Time=0.0118\n",
      "INFO     10:32:07     Epoch time: 3.2561, Total time: 87.1654\n",
      "INFO     10:32:07     Evaluating...\n",
      "INFO     10:32:09     [32: 157]: eps=0.003536355409 CE=0.6613 Err=0.2445 Loss=0.7104 Robust_CE=0.7104 Verified_Err=0.2614 Time=0.0031\n",
      "INFO     10:32:09     Epoch 33, learning rate [0.0005]\n",
      "INFO     10:32:11     [33:  50]: eps=0.003736383450 CE=0.0000 grad_norm=0.7772 Loss=0.0476 Robust_CE=0.0476 Time=0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:32:11     [33: 100]: eps=0.003944779537 CE=0.0000 grad_norm=0.7796 Loss=0.0477 Robust_CE=0.0477 Time=0.0121\n",
      "INFO     10:32:12     [33: 150]: eps=0.004161773858 CE=0.0000 grad_norm=0.7894 Loss=0.0480 Robust_CE=0.0480 Time=0.0120\n",
      "INFO     10:32:12     [33: 157]: eps=0.004192852446 CE=0.0000 grad_norm=0.7946 Loss=0.0480 Robust_CE=0.0480 Time=0.0120\n",
      "INFO     10:32:12     Epoch time: 3.2434, Total time: 90.4088\n",
      "INFO     10:32:12     Evaluating...\n",
      "INFO     10:32:14     [33: 157]: eps=0.004192852446 CE=0.6632 Err=0.2450 Loss=0.7224 Robust_CE=0.7224 Verified_Err=0.2674 Time=0.0031\n",
      "INFO     10:32:14     Epoch 34, learning rate [0.0005]\n",
      "INFO     10:32:16     [34:  50]: eps=0.004419933528 CE=0.0000 grad_norm=0.7289 Loss=0.0431 Robust_CE=0.0431 Time=0.0121\n",
      "INFO     10:32:16     [34: 100]: eps=0.004653590872 CE=0.0000 grad_norm=0.7212 Loss=0.0433 Robust_CE=0.0433 Time=0.0120\n",
      "INFO     10:32:17     [34: 150]: eps=0.004887557230 CE=0.0000 grad_norm=0.7269 Loss=0.0439 Robust_CE=0.0439 Time=0.0119\n",
      "INFO     10:32:17     [34: 157]: eps=0.004920312521 CE=0.0000 grad_norm=0.7349 Loss=0.0440 Robust_CE=0.0440 Time=0.0119\n",
      "INFO     10:32:17     Epoch time: 3.2187, Total time: 93.6275\n",
      "INFO     10:32:17     Evaluating...\n",
      "INFO     10:32:19     [34: 157]: eps=0.004920312521 CE=0.6627 Err=0.2436 Loss=0.7336 Robust_CE=0.7336 Verified_Err=0.2693 Time=0.0030\n",
      "INFO     10:32:19     Epoch 35, learning rate [0.0005]\n",
      "INFO     10:32:21     [35:  50]: eps=0.005154278879 CE=0.0000 grad_norm=0.7100 Loss=0.0420 Robust_CE=0.0420 Time=0.0120\n",
      "INFO     10:32:21     [35: 100]: eps=0.005388245238 CE=0.0000 grad_norm=0.6938 Loss=0.0412 Robust_CE=0.0412 Time=0.0119\n",
      "INFO     10:32:22     [35: 150]: eps=0.005622211596 CE=0.0000 grad_norm=0.7088 Loss=0.0418 Robust_CE=0.0418 Time=0.0118\n",
      "INFO     10:32:22     [35: 157]: eps=0.005654966886 CE=0.0000 grad_norm=0.7165 Loss=0.0419 Robust_CE=0.0419 Time=0.0118\n",
      "INFO     10:32:22     Epoch time: 3.2550, Total time: 96.8825\n",
      "INFO     10:32:22     Evaluating...\n",
      "INFO     10:32:24     [35: 157]: eps=0.005654966886 CE=0.6693 Err=0.2456 Loss=0.7526 Robust_CE=0.7526 Verified_Err=0.2726 Time=0.0034\n",
      "INFO     10:32:24     Epoch 36, learning rate [0.0005]\n",
      "INFO     10:32:26     [36:  50]: eps=0.005888933245 CE=0.0000 grad_norm=0.6529 Loss=0.0384 Robust_CE=0.0384 Time=0.0159\n",
      "INFO     10:32:27     [36: 100]: eps=0.006122899604 CE=0.0000 grad_norm=0.6713 Loss=0.0385 Robust_CE=0.0385 Time=0.0158\n",
      "INFO     10:32:28     [36: 150]: eps=0.006356865962 CE=0.0000 grad_norm=0.6731 Loss=0.0389 Robust_CE=0.0389 Time=0.0157\n",
      "INFO     10:32:28     [36: 157]: eps=0.006389621252 CE=0.0000 grad_norm=0.6774 Loss=0.0389 Robust_CE=0.0389 Time=0.0156\n",
      "INFO     10:32:28     Epoch time: 4.1494, Total time: 101.0319\n",
      "INFO     10:32:28     Evaluating...\n",
      "INFO     10:32:31     [36: 157]: eps=0.006389621252 CE=0.6851 Err=0.2497 Loss=0.7818 Robust_CE=0.7818 Verified_Err=0.2857 Time=0.0035\n",
      "INFO     10:32:31     Epoch 37, learning rate [0.0005]\n",
      "INFO     10:32:33     [37:  50]: eps=0.006623587611 CE=0.0000 grad_norm=0.6926 Loss=0.0370 Robust_CE=0.0370 Time=0.0123\n",
      "INFO     10:32:33     [37: 100]: eps=0.006857553969 CE=0.0000 grad_norm=0.6580 Loss=0.0366 Robust_CE=0.0366 Time=0.0120\n",
      "INFO     10:32:34     [37: 150]: eps=0.007091520328 CE=0.0000 grad_norm=0.6721 Loss=0.0371 Robust_CE=0.0371 Time=0.0123\n",
      "INFO     10:32:34     [37: 157]: eps=0.007124275618 CE=0.0000 grad_norm=0.6692 Loss=0.0371 Robust_CE=0.0371 Time=0.0124\n",
      "INFO     10:32:34     Epoch time: 3.5693, Total time: 104.6013\n",
      "INFO     10:32:34     Evaluating...\n",
      "INFO     10:32:36     [37: 157]: eps=0.007124275618 CE=0.6842 Err=0.2492 Loss=0.7945 Robust_CE=0.7945 Verified_Err=0.2898 Time=0.0032\n",
      "INFO     10:32:36     Epoch 38, learning rate [0.0005]\n",
      "INFO     10:32:38     [38:  50]: eps=0.007358241977 CE=0.0000 grad_norm=0.6029 Loss=0.0336 Robust_CE=0.0336 Time=0.0121\n",
      "INFO     10:32:39     [38: 100]: eps=0.007592208335 CE=0.0000 grad_norm=0.5942 Loss=0.0340 Robust_CE=0.0340 Time=0.0119\n",
      "INFO     10:32:39     [38: 150]: eps=0.007826174694 CE=0.0000 grad_norm=0.6025 Loss=0.0342 Robust_CE=0.0342 Time=0.0118\n",
      "INFO     10:32:40     [38: 157]: eps=0.007858929984 CE=0.0000 grad_norm=0.6055 Loss=0.0343 Robust_CE=0.0343 Time=0.0118\n",
      "INFO     10:32:40     Epoch time: 3.2515, Total time: 107.8527\n",
      "INFO     10:32:40     Evaluating...\n",
      "INFO     10:32:42     [38: 157]: eps=0.007858929984 CE=0.6912 Err=0.2479 Loss=0.8149 Robust_CE=0.8149 Verified_Err=0.2921 Time=0.0030\n",
      "INFO     10:32:42     Epoch 39, learning rate [0.0005]\n",
      "INFO     10:32:43     [39:  50]: eps=0.008092896343 CE=0.0000 grad_norm=0.6320 Loss=0.0326 Robust_CE=0.0326 Time=0.0120\n",
      "INFO     10:32:44     [39: 100]: eps=0.008326862701 CE=0.0000 grad_norm=0.6532 Loss=0.0332 Robust_CE=0.0332 Time=0.0118\n",
      "INFO     10:32:45     [39: 150]: eps=0.008560829060 CE=0.0000 grad_norm=0.6334 Loss=0.0330 Robust_CE=0.0330 Time=0.0118\n",
      "INFO     10:32:45     [39: 157]: eps=0.008593584350 CE=0.0000 grad_norm=0.6341 Loss=0.0330 Robust_CE=0.0330 Time=0.0118\n",
      "INFO     10:32:45     Epoch time: 3.3033, Total time: 111.1560\n",
      "INFO     10:32:45     Evaluating...\n",
      "INFO     10:32:47     [39: 157]: eps=0.008593584350 CE=0.6949 Err=0.2513 Loss=0.8331 Robust_CE=0.8331 Verified_Err=0.2982 Time=0.0030\n",
      "INFO     10:32:47     Epoch 40, learning rate [0.0005]\n",
      "INFO     10:32:49     [40:  50]: eps=0.008827550709 CE=0.0000 grad_norm=0.5124 Loss=0.0298 Robust_CE=0.0298 Time=0.0122\n",
      "INFO     10:32:49     [40: 100]: eps=0.009061517067 CE=0.0000 grad_norm=0.5336 Loss=0.0301 Robust_CE=0.0301 Time=0.0121\n",
      "INFO     10:32:50     [40: 150]: eps=0.009295483426 CE=0.0000 grad_norm=0.5630 Loss=0.0308 Robust_CE=0.0308 Time=0.0120\n",
      "INFO     10:32:50     [40: 157]: eps=0.009328238716 CE=0.0000 grad_norm=0.5668 Loss=0.0309 Robust_CE=0.0309 Time=0.0119\n",
      "INFO     10:32:50     Epoch time: 3.2664, Total time: 114.4225\n",
      "INFO     10:32:50     Evaluating...\n",
      "INFO     10:32:52     [40: 157]: eps=0.009328238716 CE=0.6889 Err=0.2479 Loss=0.8417 Robust_CE=0.8417 Verified_Err=0.2998 Time=0.0037\n",
      "INFO     10:32:52     Epoch 41, learning rate [0.0005]\n",
      "INFO     10:32:54     [41:  50]: eps=0.009562205074 CE=0.0000 grad_norm=0.5778 Loss=0.0297 Robust_CE=0.0297 Time=0.0155\n",
      "INFO     10:32:55     [41: 100]: eps=0.009796171433 CE=0.0000 grad_norm=0.5618 Loss=0.0296 Robust_CE=0.0296 Time=0.0142\n",
      "INFO     10:32:56     [41: 150]: eps=0.010030137792 CE=0.0000 grad_norm=0.5597 Loss=0.0296 Robust_CE=0.0296 Time=0.0139\n",
      "INFO     10:32:56     [41: 157]: eps=0.010062893082 CE=0.0000 grad_norm=0.5644 Loss=0.0296 Robust_CE=0.0296 Time=0.0138\n",
      "INFO     10:32:56     Epoch time: 4.0139, Total time: 118.4364\n",
      "INFO     10:32:56     Evaluating...\n",
      "INFO     10:32:58     [41: 157]: eps=0.010062893082 CE=0.7038 Err=0.2532 Loss=0.8727 Robust_CE=0.8727 Verified_Err=0.3075 Time=0.0035\n",
      "INFO     10:32:58     Epoch 42, learning rate [0.0005]\n",
      "INFO     10:33:00     [42:  50]: eps=0.010296859440 CE=0.0000 grad_norm=0.5043 Loss=0.0266 Robust_CE=0.0266 Time=0.0127\n",
      "INFO     10:33:01     [42: 100]: eps=0.010530825799 CE=0.0000 grad_norm=0.5153 Loss=0.0270 Robust_CE=0.0270 Time=0.0125\n",
      "INFO     10:33:02     [42: 150]: eps=0.010764792157 CE=0.0000 grad_norm=0.5380 Loss=0.0279 Robust_CE=0.0279 Time=0.0125\n",
      "INFO     10:33:02     [42: 157]: eps=0.010797547448 CE=0.0000 grad_norm=0.5392 Loss=0.0280 Robust_CE=0.0280 Time=0.0124\n",
      "INFO     10:33:02     Epoch time: 3.5854, Total time: 122.0218\n",
      "INFO     10:33:02     Evaluating...\n",
      "INFO     10:33:04     [42: 157]: eps=0.010797547448 CE=0.7062 Err=0.2516 Loss=0.8912 Robust_CE=0.8912 Verified_Err=0.3139 Time=0.0038\n",
      "INFO     10:33:04     Epoch 43, learning rate [0.0005]\n",
      "INFO     10:33:06     [43:  50]: eps=0.011031513806 CE=0.0000 grad_norm=0.5065 Loss=0.0258 Robust_CE=0.0258 Time=0.0122\n",
      "INFO     10:33:07     [43: 100]: eps=0.011265480165 CE=0.0000 grad_norm=0.4978 Loss=0.0258 Robust_CE=0.0258 Time=0.0117\n",
      "INFO     10:33:07     [43: 150]: eps=0.011499446523 CE=0.0000 grad_norm=0.5175 Loss=0.0267 Robust_CE=0.0267 Time=0.0115\n",
      "INFO     10:33:08     [43: 157]: eps=0.011532201814 CE=0.0000 grad_norm=0.5244 Loss=0.0267 Robust_CE=0.0267 Time=0.0115\n",
      "INFO     10:33:08     Epoch time: 3.3095, Total time: 125.3313\n",
      "INFO     10:33:08     Evaluating...\n",
      "INFO     10:33:10     [43: 157]: eps=0.011532201814 CE=0.7130 Err=0.2542 Loss=0.9146 Robust_CE=0.9146 Verified_Err=0.3186 Time=0.0030\n",
      "INFO     10:33:10     Epoch 44, learning rate [0.0005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:33:11     [44:  50]: eps=0.011766168172 CE=0.0000 grad_norm=0.4859 Loss=0.0243 Robust_CE=0.0243 Time=0.0119\n",
      "INFO     10:33:12     [44: 100]: eps=0.012000134531 CE=0.0000 grad_norm=0.4665 Loss=0.0241 Robust_CE=0.0241 Time=0.0118\n",
      "INFO     10:33:12     [44: 150]: eps=0.012234100889 CE=0.0000 grad_norm=0.4877 Loss=0.0251 Robust_CE=0.0251 Time=0.0117\n",
      "INFO     10:33:13     [44: 157]: eps=0.012266856179 CE=0.0000 grad_norm=0.4932 Loss=0.0253 Robust_CE=0.0253 Time=0.0117\n",
      "INFO     10:33:13     Epoch time: 3.2560, Total time: 128.5873\n",
      "INFO     10:33:13     Evaluating...\n",
      "INFO     10:33:15     [44: 157]: eps=0.012266856179 CE=0.7092 Err=0.2524 Loss=0.9277 Robust_CE=0.9277 Verified_Err=0.3196 Time=0.0029\n",
      "INFO     10:33:15     Epoch 45, learning rate [0.0005]\n",
      "INFO     10:33:16     [45:  50]: eps=0.012500822538 CE=0.0000 grad_norm=0.4548 Loss=0.0234 Robust_CE=0.0234 Time=0.0120\n",
      "INFO     10:33:17     [45: 100]: eps=0.012734788897 CE=0.0000 grad_norm=0.4635 Loss=0.0236 Robust_CE=0.0236 Time=0.0119\n",
      "INFO     10:33:18     [45: 150]: eps=0.012968755255 CE=0.0000 grad_norm=0.4770 Loss=0.0241 Robust_CE=0.0241 Time=0.0118\n",
      "INFO     10:33:18     [45: 157]: eps=0.013001510545 CE=0.0000 grad_norm=0.4849 Loss=0.0241 Robust_CE=0.0241 Time=0.0118\n",
      "INFO     10:33:18     Epoch time: 3.2446, Total time: 131.8318\n",
      "INFO     10:33:18     Evaluating...\n",
      "INFO     10:33:20     [45: 157]: eps=0.013001510545 CE=0.7356 Err=0.2550 Loss=0.9740 Robust_CE=0.9740 Verified_Err=0.3300 Time=0.0031\n",
      "INFO     10:33:20     Epoch 46, learning rate [0.0005]\n",
      "INFO     10:33:22     [46:  50]: eps=0.013235476904 CE=0.0000 grad_norm=0.4765 Loss=0.0231 Robust_CE=0.0231 Time=0.0120\n",
      "INFO     10:33:22     [46: 100]: eps=0.013469443262 CE=0.0000 grad_norm=0.4816 Loss=0.0233 Robust_CE=0.0233 Time=0.0118\n",
      "INFO     10:33:23     [46: 150]: eps=0.013703409621 CE=0.0000 grad_norm=0.5081 Loss=0.0240 Robust_CE=0.0240 Time=0.0118\n",
      "INFO     10:33:23     [46: 157]: eps=0.013736164911 CE=0.0000 grad_norm=0.5171 Loss=0.0241 Robust_CE=0.0241 Time=0.0118\n",
      "INFO     10:33:23     Epoch time: 3.2404, Total time: 135.0722\n",
      "INFO     10:33:23     Evaluating...\n",
      "INFO     10:33:25     [46: 157]: eps=0.013736164911 CE=0.7290 Err=0.2552 Loss=0.9849 Robust_CE=0.9849 Verified_Err=0.3315 Time=0.0030\n",
      "INFO     10:33:25     Epoch 47, learning rate [0.0005]\n",
      "INFO     10:33:27     [47:  50]: eps=0.013970131270 CE=0.0000 grad_norm=0.4707 Loss=0.0223 Robust_CE=0.0223 Time=0.0123\n",
      "INFO     10:33:27     [47: 100]: eps=0.014204097628 CE=0.0000 grad_norm=0.4665 Loss=0.0224 Robust_CE=0.0224 Time=0.0124\n",
      "INFO     10:33:28     [47: 150]: eps=0.014438063987 CE=0.0000 grad_norm=0.4770 Loss=0.0228 Robust_CE=0.0228 Time=0.0129\n",
      "INFO     10:33:28     [47: 157]: eps=0.014470819277 CE=0.0000 grad_norm=0.4775 Loss=0.0228 Robust_CE=0.0228 Time=0.0128\n",
      "INFO     10:33:28     Epoch time: 3.4671, Total time: 138.5393\n",
      "INFO     10:33:28     Evaluating...\n",
      "INFO     10:33:31     [47: 157]: eps=0.014470819277 CE=0.7292 Err=0.2569 Loss=1.0039 Robust_CE=1.0039 Verified_Err=0.3345 Time=0.0040\n",
      "INFO     10:33:31     Epoch 48, learning rate [0.0005]\n",
      "INFO     10:33:33     [48:  50]: eps=0.014704785636 CE=0.0000 grad_norm=0.4603 Loss=0.0216 Robust_CE=0.0216 Time=0.0134\n",
      "INFO     10:33:34     [48: 100]: eps=0.014938751994 CE=0.0000 grad_norm=0.4673 Loss=0.0217 Robust_CE=0.0217 Time=0.0128\n",
      "INFO     10:33:34     [48: 150]: eps=0.015172718353 CE=0.0000 grad_norm=0.4746 Loss=0.0220 Robust_CE=0.0220 Time=0.0120\n",
      "INFO     10:33:34     [48: 157]: eps=0.015205473643 CE=0.0000 grad_norm=0.4780 Loss=0.0221 Robust_CE=0.0221 Time=0.0119\n",
      "INFO     10:33:34     Epoch time: 3.6242, Total time: 142.1635\n",
      "INFO     10:33:34     Evaluating...\n",
      "INFO     10:33:37     [48: 157]: eps=0.015205473643 CE=0.7356 Err=0.2569 Loss=1.0306 Robust_CE=1.0306 Verified_Err=0.3395 Time=0.0034\n",
      "INFO     10:33:37     Epoch 49, learning rate [0.0005]\n",
      "INFO     10:33:39     [49:  50]: eps=0.015439440002 CE=0.0000 grad_norm=0.4201 Loss=0.0198 Robust_CE=0.0198 Time=0.0129\n",
      "INFO     10:33:39     [49: 100]: eps=0.015673406360 CE=0.0000 grad_norm=0.4391 Loss=0.0205 Robust_CE=0.0205 Time=0.0121\n",
      "INFO     10:33:40     [49: 150]: eps=0.015907372719 CE=0.0000 grad_norm=0.4349 Loss=0.0208 Robust_CE=0.0208 Time=0.0120\n",
      "INFO     10:33:40     [49: 157]: eps=0.015940128009 CE=0.0000 grad_norm=0.4396 Loss=0.0209 Robust_CE=0.0209 Time=0.0119\n",
      "INFO     10:33:40     Epoch time: 3.5699, Total time: 145.7335\n",
      "INFO     10:33:40     Evaluating...\n",
      "INFO     10:33:43     [49: 157]: eps=0.015940128009 CE=0.7500 Err=0.2585 Loss=1.0666 Robust_CE=1.0666 Verified_Err=0.3483 Time=0.0043\n",
      "INFO     10:33:43     Epoch 50, learning rate [0.0005]\n",
      "INFO     10:33:45     [50:  50]: eps=0.016174094367 CE=0.0000 grad_norm=0.4409 Loss=0.0202 Robust_CE=0.0202 Time=0.0119\n",
      "INFO     10:33:45     [50: 100]: eps=0.016408060726 CE=0.0000 grad_norm=0.4588 Loss=0.0205 Robust_CE=0.0205 Time=0.0116\n",
      "INFO     10:33:46     [50: 150]: eps=0.016642027085 CE=0.0000 grad_norm=0.5468 Loss=0.0230 Robust_CE=0.0230 Time=0.0115\n",
      "INFO     10:33:46     [50: 157]: eps=0.016674782375 CE=0.0000 grad_norm=0.5806 Loss=0.0239 Robust_CE=0.0239 Time=0.0115\n",
      "INFO     10:33:46     Epoch time: 3.3637, Total time: 149.0972\n",
      "INFO     10:33:46     Evaluating...\n",
      "INFO     10:33:48     [50: 157]: eps=0.016674782375 CE=0.8204 Err=0.2684 Loss=1.1650 Robust_CE=1.1650 Verified_Err=0.3570 Time=0.0032\n",
      "INFO     10:33:48     Epoch 51, learning rate [0.0005]\n",
      "INFO     10:33:50     [51:  50]: eps=0.016908748733 CE=0.0000 grad_norm=0.6095 Loss=0.0247 Robust_CE=0.0247 Time=0.0120\n",
      "INFO     10:33:50     [51: 100]: eps=0.017142715092 CE=0.0000 grad_norm=0.5070 Loss=0.0220 Robust_CE=0.0220 Time=0.0118\n",
      "INFO     10:33:51     [51: 150]: eps=0.017376681450 CE=0.0000 grad_norm=0.5068 Loss=0.0218 Robust_CE=0.0218 Time=0.0118\n",
      "INFO     10:33:51     [51: 157]: eps=0.017409436741 CE=0.0000 grad_norm=0.5091 Loss=0.0217 Robust_CE=0.0217 Time=0.0118\n",
      "INFO     10:33:51     Epoch time: 3.2816, Total time: 152.3788\n",
      "INFO     10:33:51     Evaluating...\n",
      "INFO     10:33:53     [51: 157]: eps=0.017409436741 CE=0.7937 Err=0.2653 Loss=1.1578 Robust_CE=1.1578 Verified_Err=0.3601 Time=0.0030\n",
      "INFO     10:33:53     Epoch 52, learning rate [0.0005]\n",
      "INFO     10:33:55     [52:  50]: eps=0.017643403099 CE=0.0000 grad_norm=0.4573 Loss=0.0188 Robust_CE=0.0188 Time=0.0120\n",
      "INFO     10:33:56     [52: 100]: eps=0.017877369458 CE=0.0000 grad_norm=0.4252 Loss=0.0186 Robust_CE=0.0186 Time=0.0121\n",
      "INFO     10:33:56     [52: 150]: eps=0.018111335816 CE=0.0000 grad_norm=0.4589 Loss=0.0195 Robust_CE=0.0195 Time=0.0119\n",
      "INFO     10:33:56     [52: 157]: eps=0.018144091107 CE=0.0000 grad_norm=0.4647 Loss=0.0196 Robust_CE=0.0196 Time=0.0119\n",
      "INFO     10:33:56     Epoch time: 3.2741, Total time: 155.6530\n",
      "INFO     10:33:56     Evaluating...\n",
      "INFO     10:33:58     [52: 157]: eps=0.018144091107 CE=0.8036 Err=0.2644 Loss=1.1912 Robust_CE=1.1912 Verified_Err=0.3671 Time=0.0030\n",
      "INFO     10:33:58     Epoch 53, learning rate [0.0005]\n",
      "INFO     10:34:00     [53:  50]: eps=0.018378057465 CE=0.0000 grad_norm=0.4713 Loss=0.0188 Robust_CE=0.0188 Time=0.0120\n",
      "INFO     10:34:01     [53: 100]: eps=0.018612023824 CE=0.0000 grad_norm=0.4490 Loss=0.0186 Robust_CE=0.0186 Time=0.0119\n",
      "INFO     10:34:01     [53: 150]: eps=0.018845990182 CE=0.0000 grad_norm=0.4583 Loss=0.0190 Robust_CE=0.0190 Time=0.0118\n",
      "INFO     10:34:02     [53: 157]: eps=0.018878745472 CE=0.0000 grad_norm=0.4670 Loss=0.0190 Robust_CE=0.0190 Time=0.0119\n",
      "INFO     10:34:02     Epoch time: 3.2762, Total time: 158.9292\n",
      "INFO     10:34:02     Evaluating...\n",
      "INFO     10:34:04     [53: 157]: eps=0.018878745472 CE=0.8081 Err=0.2673 Loss=1.2195 Robust_CE=1.2195 Verified_Err=0.3680 Time=0.0031\n",
      "INFO     10:34:04     Epoch 54, learning rate [0.0005]\n",
      "INFO     10:34:05     [54:  50]: eps=0.019112711831 CE=0.0000 grad_norm=0.4756 Loss=0.0192 Robust_CE=0.0192 Time=0.0120\n",
      "INFO     10:34:06     [54: 100]: eps=0.019346678190 CE=0.0000 grad_norm=0.4190 Loss=0.0181 Robust_CE=0.0181 Time=0.0118\n",
      "INFO     10:34:06     [54: 150]: eps=0.019580644548 CE=0.0000 grad_norm=0.4040 Loss=0.0180 Robust_CE=0.0180 Time=0.0118\n",
      "INFO     10:34:07     [54: 157]: eps=0.019613399838 CE=0.0000 grad_norm=0.4096 Loss=0.0181 Robust_CE=0.0181 Time=0.0118\n",
      "INFO     10:34:07     Epoch time: 3.2527, Total time: 162.1818\n",
      "INFO     10:34:07     Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:34:09     [54: 157]: eps=0.019613399838 CE=0.7898 Err=0.2596 Loss=1.2206 Robust_CE=1.2206 Verified_Err=0.3704 Time=0.0031\n",
      "INFO     10:34:09     Epoch 55, learning rate [0.0005]\n",
      "INFO     10:34:10     [55:  50]: eps=0.019847366197 CE=0.0000 grad_norm=0.3792 Loss=0.0159 Robust_CE=0.0159 Time=0.0132\n",
      "INFO     10:34:11     [55: 100]: eps=0.020081332555 CE=0.0000 grad_norm=0.4146 Loss=0.0172 Robust_CE=0.0172 Time=0.0125\n",
      "INFO     10:34:12     [55: 150]: eps=0.020315298914 CE=0.0000 grad_norm=0.4396 Loss=0.0179 Robust_CE=0.0179 Time=0.0123\n",
      "INFO     10:34:12     [55: 157]: eps=0.020348054204 CE=0.0000 grad_norm=0.4465 Loss=0.0180 Robust_CE=0.0180 Time=0.0123\n",
      "INFO     10:34:12     Epoch time: 3.3324, Total time: 165.5143\n",
      "INFO     10:34:12     Evaluating...\n",
      "INFO     10:34:14     [55: 157]: eps=0.020348054204 CE=0.8070 Err=0.2632 Loss=1.2666 Robust_CE=1.2666 Verified_Err=0.3829 Time=0.0031\n",
      "INFO     10:34:14     Epoch 56, learning rate [0.0005]\n",
      "INFO     10:34:16     [56:  50]: eps=0.020582020563 CE=0.0000 grad_norm=0.4697 Loss=0.0176 Robust_CE=0.0176 Time=0.0121\n",
      "INFO     10:34:16     [56: 100]: eps=0.020815986921 CE=0.0000 grad_norm=0.4309 Loss=0.0173 Robust_CE=0.0173 Time=0.0119\n",
      "INFO     10:34:17     [56: 150]: eps=0.021049953280 CE=0.0000 grad_norm=0.4207 Loss=0.0174 Robust_CE=0.0174 Time=0.0119\n",
      "INFO     10:34:17     [56: 157]: eps=0.021082708570 CE=0.0000 grad_norm=0.4245 Loss=0.0175 Robust_CE=0.0175 Time=0.0118\n",
      "INFO     10:34:17     Epoch time: 3.2562, Total time: 168.7705\n",
      "INFO     10:34:17     Evaluating...\n",
      "INFO     10:34:19     [56: 157]: eps=0.021082708570 CE=0.8166 Err=0.2643 Loss=1.3017 Robust_CE=1.3017 Verified_Err=0.3834 Time=0.0031\n",
      "INFO     10:34:19     Epoch 57, learning rate [0.0005]\n",
      "INFO     10:34:21     [57:  50]: eps=0.021316674929 CE=0.0000 grad_norm=0.3847 Loss=0.0160 Robust_CE=0.0160 Time=0.0121\n",
      "INFO     10:34:21     [57: 100]: eps=0.021550641287 CE=0.0000 grad_norm=0.4002 Loss=0.0179 Robust_CE=0.0179 Time=0.0119\n",
      "INFO     10:34:22     [57: 150]: eps=0.021784607646 CE=0.0000 grad_norm=0.4404 Loss=0.0184 Robust_CE=0.0184 Time=0.0119\n",
      "INFO     10:34:22     [57: 157]: eps=0.021817362936 CE=0.0000 grad_norm=0.4610 Loss=0.0184 Robust_CE=0.0184 Time=0.0118\n",
      "INFO     10:34:22     Epoch time: 3.2633, Total time: 172.0338\n",
      "INFO     10:34:22     Evaluating...\n",
      "INFO     10:34:24     [57: 157]: eps=0.021817362936 CE=0.8168 Err=0.2616 Loss=1.3263 Robust_CE=1.3263 Verified_Err=0.3824 Time=0.0031\n",
      "INFO     10:34:24     Epoch 58, learning rate [0.0005]\n",
      "INFO     10:34:26     [58:  50]: eps=0.022051329294 CE=0.0000 grad_norm=0.4883 Loss=0.0188 Robust_CE=0.0188 Time=0.0121\n",
      "INFO     10:34:27     [58: 100]: eps=0.022285295653 CE=0.0000 grad_norm=0.4227 Loss=0.0173 Robust_CE=0.0173 Time=0.0120\n",
      "INFO     10:34:27     [58: 150]: eps=0.022519262012 CE=0.0000 grad_norm=0.4296 Loss=0.0172 Robust_CE=0.0172 Time=0.0119\n",
      "INFO     10:34:27     [58: 157]: eps=0.022552017302 CE=0.0000 grad_norm=0.4371 Loss=0.0173 Robust_CE=0.0173 Time=0.0118\n",
      "INFO     10:34:27     Epoch time: 3.2603, Total time: 175.2942\n",
      "INFO     10:34:27     Evaluating...\n",
      "INFO     10:34:29     [58: 157]: eps=0.022552017302 CE=0.8481 Err=0.2629 Loss=1.3878 Robust_CE=1.3878 Verified_Err=0.3928 Time=0.0031\n",
      "INFO     10:34:29     Epoch 59, learning rate [0.0005]\n",
      "INFO     10:34:31     [59:  50]: eps=0.022785983660 CE=0.0000 grad_norm=0.4186 Loss=0.0161 Robust_CE=0.0161 Time=0.0121\n",
      "INFO     10:34:32     [59: 100]: eps=0.023019950019 CE=0.0000 grad_norm=0.4529 Loss=0.0168 Robust_CE=0.0168 Time=0.0120\n",
      "INFO     10:34:32     [59: 150]: eps=0.023253916377 CE=0.0000 grad_norm=0.4787 Loss=0.0173 Robust_CE=0.0173 Time=0.0119\n",
      "INFO     10:34:33     [59: 157]: eps=0.023286671668 CE=0.0000 grad_norm=0.4861 Loss=0.0175 Robust_CE=0.0175 Time=0.0119\n",
      "INFO     10:34:33     Epoch time: 3.2624, Total time: 178.5566\n",
      "INFO     10:34:33     Evaluating...\n",
      "INFO     10:34:34     [59: 157]: eps=0.023286671668 CE=0.8450 Err=0.2658 Loss=1.4130 Robust_CE=1.4130 Verified_Err=0.3961 Time=0.0031\n",
      "INFO     10:34:34     Epoch 60, learning rate [0.0005]\n",
      "INFO     10:34:36     [60:  50]: eps=0.023520638026 CE=0.0000 grad_norm=0.5570 Loss=0.0273 Robust_CE=0.0273 Time=0.0121\n",
      "INFO     10:34:37     [60: 100]: eps=0.023754604385 CE=0.0000 grad_norm=0.8016 Loss=0.0433 Robust_CE=0.0433 Time=0.0119\n",
      "INFO     10:34:37     [60: 150]: eps=0.023988570743 CE=0.0000 grad_norm=0.9697 Loss=0.0520 Robust_CE=0.0520 Time=0.0118\n",
      "INFO     10:34:38     [60: 157]: eps=0.024021326034 CE=0.0000 grad_norm=0.9859 Loss=0.0520 Robust_CE=0.0520 Time=0.0118\n",
      "INFO     10:34:38     Epoch time: 3.2442, Total time: 181.8008\n",
      "INFO     10:34:38     Evaluating...\n",
      "INFO     10:34:40     [60: 157]: eps=0.024021326034 CE=0.9791 Err=0.2880 Loss=1.5983 Robust_CE=1.5983 Verified_Err=0.4136 Time=0.0031\n",
      "INFO     10:34:40     Epoch 61, learning rate [0.0005]\n",
      "INFO     10:34:41     [61:  50]: eps=0.024255292392 CE=0.0000 grad_norm=0.9803 Loss=0.0550 Robust_CE=0.0550 Time=0.0121\n",
      "INFO     10:34:42     [61: 100]: eps=0.024489258751 CE=0.0000 grad_norm=0.9399 Loss=0.0465 Robust_CE=0.0465 Time=0.0119\n",
      "INFO     10:34:43     [61: 150]: eps=0.024723225109 CE=0.0000 grad_norm=0.9003 Loss=0.0428 Robust_CE=0.0428 Time=0.0119\n",
      "INFO     10:34:43     [61: 157]: eps=0.024755980399 CE=0.0000 grad_norm=0.8989 Loss=0.0436 Robust_CE=0.0436 Time=0.0118\n",
      "INFO     10:34:43     Epoch time: 3.2457, Total time: 185.0465\n",
      "INFO     10:34:43     Evaluating...\n",
      "INFO     10:34:45     [61: 157]: eps=0.024755980399 CE=0.8893 Err=0.2705 Loss=1.5209 Robust_CE=1.5209 Verified_Err=0.4082 Time=0.0031\n",
      "INFO     10:34:45     Epoch 62, learning rate [0.0005]\n",
      "INFO     10:34:46     [62:  50]: eps=0.024989946758 CE=0.0000 grad_norm=0.5098 Loss=0.0214 Robust_CE=0.0214 Time=0.0122\n",
      "INFO     10:34:47     [62: 100]: eps=0.025223913117 CE=0.0000 grad_norm=0.5367 Loss=0.0199 Robust_CE=0.0199 Time=0.0120\n",
      "INFO     10:34:48     [62: 150]: eps=0.025457879475 CE=0.0000 grad_norm=0.5697 Loss=0.0205 Robust_CE=0.0205 Time=0.0120\n",
      "INFO     10:34:48     [62: 157]: eps=0.025490634765 CE=0.0000 grad_norm=0.5670 Loss=0.0203 Robust_CE=0.0203 Time=0.0119\n",
      "INFO     10:34:48     Epoch time: 3.2559, Total time: 188.3024\n",
      "INFO     10:34:48     Evaluating...\n",
      "INFO     10:34:50     [62: 157]: eps=0.025490634765 CE=0.8802 Err=0.2688 Loss=1.5365 Robust_CE=1.5365 Verified_Err=0.4100 Time=0.0031\n",
      "INFO     10:34:50     Epoch 63, learning rate [0.0005]\n",
      "INFO     10:34:52     [63:  50]: eps=0.025724601124 CE=0.0000 grad_norm=0.3920 Loss=0.0157 Robust_CE=0.0157 Time=0.0121\n",
      "INFO     10:34:52     [63: 100]: eps=0.025958567482 CE=0.0000 grad_norm=0.3669 Loss=0.0158 Robust_CE=0.0158 Time=0.0120\n",
      "INFO     10:34:53     [63: 150]: eps=0.026192533841 CE=0.0000 grad_norm=0.3577 Loss=0.0159 Robust_CE=0.0159 Time=0.0119\n",
      "INFO     10:34:53     [63: 157]: eps=0.026225289131 CE=0.0000 grad_norm=0.3585 Loss=0.0158 Robust_CE=0.0158 Time=0.0119\n",
      "INFO     10:34:53     Epoch time: 3.2518, Total time: 191.5541\n",
      "INFO     10:34:53     Evaluating...\n",
      "INFO     10:34:55     [63: 157]: eps=0.026225289131 CE=0.8574 Err=0.2646 Loss=1.5383 Robust_CE=1.5383 Verified_Err=0.4140 Time=0.0031\n",
      "INFO     10:34:55     Epoch 64, learning rate [0.0005]\n",
      "INFO     10:34:57     [64:  50]: eps=0.026459255490 CE=0.0000 grad_norm=0.2876 Loss=0.0140 Robust_CE=0.0140 Time=0.0121\n",
      "INFO     10:34:57     [64: 100]: eps=0.026693221848 CE=0.0000 grad_norm=0.3107 Loss=0.0147 Robust_CE=0.0147 Time=0.0120\n",
      "INFO     10:34:58     [64: 150]: eps=0.026927188207 CE=0.0000 grad_norm=0.3119 Loss=0.0147 Robust_CE=0.0147 Time=0.0119\n",
      "INFO     10:34:58     [64: 157]: eps=0.026959943497 CE=0.0000 grad_norm=0.3168 Loss=0.0149 Robust_CE=0.0149 Time=0.0119\n",
      "INFO     10:34:58     Epoch time: 3.2914, Total time: 194.8455\n",
      "INFO     10:34:58     Evaluating...\n",
      "INFO     10:35:00     [64: 157]: eps=0.026959943497 CE=0.8652 Err=0.2613 Loss=1.5753 Robust_CE=1.5753 Verified_Err=0.4164 Time=0.0031\n",
      "INFO     10:35:00     Epoch 65, learning rate [0.0005]\n",
      "INFO     10:35:02     [65:  50]: eps=0.027193909856 CE=0.0000 grad_norm=0.2958 Loss=0.0140 Robust_CE=0.0140 Time=0.0122\n",
      "INFO     10:35:03     [65: 100]: eps=0.027427876214 CE=0.0000 grad_norm=0.3191 Loss=0.0148 Robust_CE=0.0148 Time=0.0121\n",
      "INFO     10:35:03     [65: 150]: eps=0.027661842573 CE=0.0000 grad_norm=0.3277 Loss=0.0148 Robust_CE=0.0148 Time=0.0121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:35:03     [65: 157]: eps=0.027694597863 CE=0.0000 grad_norm=0.3305 Loss=0.0148 Robust_CE=0.0148 Time=0.0120\n",
      "INFO     10:35:03     Epoch time: 3.2807, Total time: 198.1263\n",
      "INFO     10:35:03     Evaluating...\n",
      "INFO     10:35:05     [65: 157]: eps=0.027694597863 CE=0.8691 Err=0.2652 Loss=1.6135 Robust_CE=1.6135 Verified_Err=0.4200 Time=0.0031\n",
      "INFO     10:35:05     Epoch 66, learning rate [0.0005]\n",
      "INFO     10:35:07     [66:  50]: eps=0.027928564222 CE=0.0000 grad_norm=0.2698 Loss=0.0132 Robust_CE=0.0132 Time=0.0122\n",
      "INFO     10:35:08     [66: 100]: eps=0.028162530580 CE=0.0000 grad_norm=0.2798 Loss=0.0138 Robust_CE=0.0138 Time=0.0121\n",
      "INFO     10:35:08     [66: 150]: eps=0.028396496939 CE=0.0000 grad_norm=0.3107 Loss=0.0143 Robust_CE=0.0143 Time=0.0120\n",
      "INFO     10:35:09     [66: 157]: eps=0.028429252229 CE=0.0000 grad_norm=0.3204 Loss=0.0148 Robust_CE=0.0148 Time=0.0120\n",
      "INFO     10:35:09     Epoch time: 3.2757, Total time: 201.4019\n",
      "INFO     10:35:09     Evaluating...\n",
      "INFO     10:35:11     [66: 157]: eps=0.028429252229 CE=0.8846 Err=0.2651 Loss=1.6586 Robust_CE=1.6586 Verified_Err=0.4271 Time=0.0034\n",
      "INFO     10:35:11     Epoch 67, learning rate [0.0005]\n",
      "INFO     10:35:12     [67:  50]: eps=0.028663218587 CE=0.0000 grad_norm=0.3066 Loss=0.0134 Robust_CE=0.0134 Time=0.0123\n",
      "INFO     10:35:13     [67: 100]: eps=0.028897184946 CE=0.0000 grad_norm=0.3817 Loss=0.0175 Robust_CE=0.0175 Time=0.0121\n",
      "INFO     10:35:14     [67: 150]: eps=0.029131151305 CE=0.0000 grad_norm=0.9170 Loss=0.2668 Robust_CE=0.2668 Time=0.0120\n",
      "INFO     10:35:14     [67: 157]: eps=0.029163906595 CE=0.0000 grad_norm=1.0189 Loss=0.3023 Robust_CE=0.3023 Time=0.0120\n",
      "INFO     10:35:14     Epoch time: 3.3111, Total time: 204.7131\n",
      "INFO     10:35:14     Evaluating...\n",
      "INFO     10:35:16     [67: 157]: eps=0.029163906595 CE=2.2026 Err=0.4071 Loss=3.2493 Robust_CE=3.2493 Verified_Err=0.5391 Time=0.0031\n",
      "INFO     10:35:16     Epoch 68, learning rate [0.0005]\n",
      "INFO     10:35:17     [68:  50]: eps=0.029397872953 CE=0.0000 grad_norm=2.6567 Loss=2.6407 Robust_CE=2.6407 Time=0.0122\n",
      "INFO     10:35:18     [68: 100]: eps=0.029631839312 CE=0.0000 grad_norm=2.6171 Loss=2.3927 Robust_CE=2.3927 Time=0.0120\n",
      "INFO     10:35:19     [68: 150]: eps=0.029865805670 CE=0.0000 grad_norm=2.6172 Loss=2.3301 Robust_CE=2.3301 Time=0.0120\n",
      "INFO     10:35:19     [68: 157]: eps=0.029898560961 CE=0.0000 grad_norm=2.6260 Loss=2.3307 Robust_CE=2.3307 Time=0.0120\n",
      "INFO     10:35:19     Epoch time: 3.2670, Total time: 207.9800\n",
      "INFO     10:35:19     Evaluating...\n",
      "INFO     10:35:21     [68: 157]: eps=0.029898560961 CE=3.7474 Err=0.5125 Loss=5.0270 Robust_CE=5.0270 Verified_Err=0.6187 Time=0.0031\n",
      "INFO     10:35:21     Epoch 69, learning rate [0.0005]\n",
      "INFO     10:35:23     [69:  50]: eps=0.030132527319 CE=0.0000 grad_norm=2.4035 Loss=3.2263 Robust_CE=3.2263 Time=0.0121\n",
      "INFO     10:35:23     [69: 100]: eps=0.030366493678 CE=0.0000 grad_norm=2.3969 Loss=3.3675 Robust_CE=3.3675 Time=0.0123\n",
      "INFO     10:35:24     [69: 150]: eps=0.030600460036 CE=0.0000 grad_norm=2.4355 Loss=3.4576 Robust_CE=3.4576 Time=0.0124\n",
      "INFO     10:35:24     [69: 157]: eps=0.030633215327 CE=0.0000 grad_norm=2.4452 Loss=3.4885 Robust_CE=3.4885 Time=0.0124\n",
      "INFO     10:35:24     Epoch time: 3.4313, Total time: 211.4113\n",
      "INFO     10:35:24     Evaluating...\n",
      "INFO     10:35:27     [69: 157]: eps=0.030633215327 CE=5.0817 Err=0.5853 Loss=6.5778 Robust_CE=6.5778 Verified_Err=0.6733 Time=0.0040\n",
      "INFO     10:35:27     Epoch 70, learning rate [0.0005]\n",
      "INFO     10:35:29     [70:  50]: eps=0.030867181685 CE=0.0000 grad_norm=2.3828 Loss=4.9681 Robust_CE=4.9681 Time=0.0140\n",
      "INFO     10:35:29     [70: 100]: eps=0.031101148044 CE=0.0000 grad_norm=2.3214 Loss=5.6430 Robust_CE=5.6430 Time=0.0134\n",
      "INFO     10:35:30     [70: 150]: eps=0.031335114402 CE=0.0000 grad_norm=2.2748 Loss=6.8764 Robust_CE=6.8764 Time=0.0130\n",
      "INFO     10:35:30     [70: 157]: eps=0.031367869692 CE=0.0000 grad_norm=2.2795 Loss=7.0165 Robust_CE=7.0165 Time=0.0128\n",
      "INFO     10:35:30     Epoch time: 3.7598, Total time: 215.1712\n",
      "INFO     10:35:30     Evaluating...\n",
      "INFO     10:35:33     [70: 157]: eps=0.031367869692 CE=11.1373 Err=0.7495 Loss=13.0348 Robust_CE=13.0348 Verified_Err=0.7920 Time=0.0032\n",
      "INFO     10:35:33     Epoch 71, learning rate [5e-05]\n",
      "INFO     10:35:34     [71:  50]: eps=0.031372549020 CE=0.0000 grad_norm=19.8585 Loss=5.8270 Robust_CE=5.8270 Time=0.0109\n",
      "INFO     10:35:35     [71: 100]: eps=0.031372549020 CE=0.0000 grad_norm=13.5009 Loss=3.2992 Robust_CE=3.2992 Time=0.0142\n",
      "INFO     10:35:36     [71: 150]: eps=0.031372549020 CE=0.0000 grad_norm=9.9530 Loss=2.2473 Robust_CE=2.2473 Time=0.0139\n",
      "INFO     10:35:37     [71: 157]: eps=0.031372549020 CE=0.0000 grad_norm=9.6225 Loss=2.1620 Robust_CE=2.1620 Time=0.0139\n",
      "INFO     10:35:37     Epoch time: 4.1494, Total time: 219.3206\n",
      "INFO     10:35:37     Evaluating...\n",
      "INFO     10:35:39     [71: 157]: eps=0.031372549020 CE=1.0158 Err=0.2874 Loss=1.9144 Robust_CE=1.9144 Verified_Err=0.4575 Time=0.0030\n",
      "INFO     10:35:39     Epoch 72, learning rate [5e-05]\n",
      "INFO     10:35:41     [72:  50]: eps=0.031372549020 CE=0.0000 grad_norm=2.0132 Loss=0.0880 Robust_CE=0.0880 Time=0.0125\n",
      "INFO     10:35:42     [72: 100]: eps=0.031372549020 CE=0.0000 grad_norm=1.8898 Loss=0.0821 Robust_CE=0.0821 Time=0.0113\n",
      "INFO     10:35:42     [72: 150]: eps=0.031372549020 CE=0.0000 grad_norm=1.8020 Loss=0.0763 Robust_CE=0.0763 Time=0.0109\n",
      "INFO     10:35:43     [72: 157]: eps=0.031372549020 CE=0.0000 grad_norm=1.7936 Loss=0.0752 Robust_CE=0.0752 Time=0.0108\n",
      "INFO     10:35:43     Epoch time: 3.4928, Total time: 222.8134\n",
      "INFO     10:35:43     Evaluating...\n",
      "INFO     10:35:45     [72: 157]: eps=0.031372549020 CE=0.9407 Err=0.2753 Loss=1.8213 Robust_CE=1.8213 Verified_Err=0.4526 Time=0.0041\n",
      "INFO     10:35:45     Epoch 73, learning rate [5e-05]\n",
      "INFO     10:35:47     [73:  50]: eps=0.031372549020 CE=0.0000 grad_norm=1.5472 Loss=0.0578 Robust_CE=0.0578 Time=0.0119\n",
      "INFO     10:35:48     [73: 100]: eps=0.031372549020 CE=0.0000 grad_norm=1.4784 Loss=0.0554 Robust_CE=0.0554 Time=0.0116\n",
      "INFO     10:35:48     [73: 150]: eps=0.031372549020 CE=0.0000 grad_norm=1.4456 Loss=0.0554 Robust_CE=0.0554 Time=0.0117\n",
      "INFO     10:35:49     [73: 157]: eps=0.031372549020 CE=0.0000 grad_norm=1.4329 Loss=0.0547 Robust_CE=0.0547 Time=0.0116\n",
      "INFO     10:35:49     Epoch time: 4.0971, Total time: 226.9106\n",
      "INFO     10:35:49     Evaluating...\n",
      "INFO     10:35:52     [73: 157]: eps=0.031372549020 CE=0.9249 Err=0.2708 Loss=1.8031 Robust_CE=1.8031 Verified_Err=0.4504 Time=0.0035\n",
      "INFO     10:35:52     Epoch 74, learning rate [5e-05]\n",
      "INFO     10:35:54     [74:  50]: eps=0.031372549020 CE=0.0000 grad_norm=1.2144 Loss=0.0468 Robust_CE=0.0468 Time=0.0115\n",
      "INFO     10:35:54     [74: 100]: eps=0.031372549020 CE=0.0000 grad_norm=1.2748 Loss=0.0494 Robust_CE=0.0494 Time=0.0111\n",
      "INFO     10:35:55     [74: 150]: eps=0.031372549020 CE=0.0000 grad_norm=1.2456 Loss=0.0472 Robust_CE=0.0472 Time=0.0112\n",
      "INFO     10:35:56     [74: 157]: eps=0.031372549020 CE=0.0000 grad_norm=1.2557 Loss=0.0472 Robust_CE=0.0472 Time=0.0111\n",
      "INFO     10:35:56     Epoch time: 3.6477, Total time: 230.5583\n",
      "INFO     10:35:56     Evaluating...\n",
      "INFO     10:35:58     [74: 157]: eps=0.031372549020 CE=0.9184 Err=0.2708 Loss=1.7964 Robust_CE=1.7964 Verified_Err=0.4484 Time=0.0035\n",
      "INFO     10:35:58     Epoch 75, learning rate [5e-05]\n",
      "INFO     10:36:00     [75:  50]: eps=0.031372549020 CE=0.0000 grad_norm=1.2324 Loss=0.0442 Robust_CE=0.0442 Time=0.0117\n",
      "INFO     10:36:00     [75: 100]: eps=0.031372549020 CE=0.0000 grad_norm=1.1722 Loss=0.0427 Robust_CE=0.0427 Time=0.0116\n",
      "INFO     10:36:01     [75: 150]: eps=0.031372549020 CE=0.0000 grad_norm=1.1653 Loss=0.0429 Robust_CE=0.0429 Time=0.0114\n",
      "INFO     10:36:01     [75: 157]: eps=0.031372549020 CE=0.0000 grad_norm=1.1549 Loss=0.0425 Robust_CE=0.0425 Time=0.0114\n",
      "INFO     10:36:01     Epoch time: 3.5112, Total time: 234.0694\n",
      "INFO     10:36:01     Evaluating...\n",
      "INFO     10:36:03     [75: 157]: eps=0.031372549020 CE=0.9146 Err=0.2712 Loss=1.7926 Robust_CE=1.7926 Verified_Err=0.4473 Time=0.0036\n",
      "INFO     10:36:03     Epoch 76, learning rate [5e-05]\n",
      "INFO     10:36:05     [76:  50]: eps=0.031372549020 CE=0.0000 grad_norm=1.0049 Loss=0.0376 Robust_CE=0.0376 Time=0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:36:06     [76: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.9951 Loss=0.0375 Robust_CE=0.0375 Time=0.0103\n",
      "INFO     10:36:06     [76: 150]: eps=0.031372549020 CE=0.0000 grad_norm=1.0293 Loss=0.0388 Robust_CE=0.0388 Time=0.0102\n",
      "INFO     10:36:07     [76: 157]: eps=0.031372549020 CE=0.0000 grad_norm=1.0342 Loss=0.0387 Robust_CE=0.0387 Time=0.0102\n",
      "INFO     10:36:07     Epoch time: 3.1140, Total time: 237.1834\n",
      "INFO     10:36:07     Evaluating...\n",
      "INFO     10:36:09     [76: 157]: eps=0.031372549020 CE=0.9144 Err=0.2707 Loss=1.7934 Robust_CE=1.7934 Verified_Err=0.4456 Time=0.0032\n",
      "INFO     10:36:09     Epoch 77, learning rate [5e-05]\n",
      "INFO     10:36:10     [77:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.9970 Loss=0.0376 Robust_CE=0.0376 Time=0.0103\n",
      "INFO     10:36:11     [77: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.9301 Loss=0.0355 Robust_CE=0.0355 Time=0.0101\n",
      "INFO     10:36:11     [77: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.9420 Loss=0.0358 Robust_CE=0.0358 Time=0.0100\n",
      "INFO     10:36:12     [77: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.9436 Loss=0.0357 Robust_CE=0.0357 Time=0.0100\n",
      "INFO     10:36:12     Epoch time: 3.0215, Total time: 240.2049\n",
      "INFO     10:36:12     Evaluating...\n",
      "INFO     10:36:14     [77: 157]: eps=0.031372549020 CE=0.9104 Err=0.2678 Loss=1.7892 Robust_CE=1.7892 Verified_Err=0.4454 Time=0.0031\n",
      "INFO     10:36:14     Epoch 78, learning rate [5e-05]\n",
      "INFO     10:36:15     [78:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.9328 Loss=0.0335 Robust_CE=0.0335 Time=0.0103\n",
      "INFO     10:36:16     [78: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.8850 Loss=0.0328 Robust_CE=0.0328 Time=0.0101\n",
      "INFO     10:36:16     [78: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.8983 Loss=0.0335 Robust_CE=0.0335 Time=0.0101\n",
      "INFO     10:36:17     [78: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.9103 Loss=0.0332 Robust_CE=0.0332 Time=0.0100\n",
      "INFO     10:36:17     Epoch time: 3.0080, Total time: 243.2129\n",
      "INFO     10:36:17     Evaluating...\n",
      "INFO     10:36:18     [78: 157]: eps=0.031372549020 CE=0.9070 Err=0.2674 Loss=1.7865 Robust_CE=1.7865 Verified_Err=0.4447 Time=0.0031\n",
      "INFO     10:36:18     Epoch 79, learning rate [5e-05]\n",
      "INFO     10:36:20     [79:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.7659 Loss=0.0295 Robust_CE=0.0295 Time=0.0104\n",
      "INFO     10:36:21     [79: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.8107 Loss=0.0307 Robust_CE=0.0307 Time=0.0102\n",
      "INFO     10:36:21     [79: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.8175 Loss=0.0311 Robust_CE=0.0311 Time=0.0101\n",
      "INFO     10:36:21     [79: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.8177 Loss=0.0311 Robust_CE=0.0311 Time=0.0101\n",
      "INFO     10:36:21     Epoch time: 3.0121, Total time: 246.2250\n",
      "INFO     10:36:21     Evaluating...\n",
      "INFO     10:36:23     [79: 157]: eps=0.031372549020 CE=0.9078 Err=0.2678 Loss=1.7884 Robust_CE=1.7884 Verified_Err=0.4446 Time=0.0031\n",
      "INFO     10:36:23     Epoch 80, learning rate [5e-05]\n",
      "INFO     10:36:25     [80:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.7094 Loss=0.0271 Robust_CE=0.0271 Time=0.0105\n",
      "INFO     10:36:26     [80: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.7423 Loss=0.0285 Robust_CE=0.0285 Time=0.0103\n",
      "INFO     10:36:26     [80: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.7615 Loss=0.0291 Robust_CE=0.0291 Time=0.0103\n",
      "INFO     10:36:26     [80: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.7653 Loss=0.0291 Robust_CE=0.0291 Time=0.0102\n",
      "INFO     10:36:26     Epoch time: 3.0438, Total time: 249.2688\n",
      "INFO     10:36:26     Evaluating...\n",
      "INFO     10:36:28     [80: 157]: eps=0.031372549020 CE=0.9044 Err=0.2679 Loss=1.7851 Robust_CE=1.7851 Verified_Err=0.4442 Time=0.0031\n",
      "INFO     10:36:28     Epoch 81, learning rate [5e-05]\n",
      "INFO     10:36:30     [81:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.7163 Loss=0.0279 Robust_CE=0.0279 Time=0.0103\n",
      "INFO     10:36:31     [81: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.6861 Loss=0.0268 Robust_CE=0.0268 Time=0.0102\n",
      "INFO     10:36:31     [81: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.7055 Loss=0.0274 Robust_CE=0.0274 Time=0.0102\n",
      "INFO     10:36:31     [81: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.7134 Loss=0.0275 Robust_CE=0.0275 Time=0.0101\n",
      "INFO     10:36:31     Epoch time: 3.0332, Total time: 252.3020\n",
      "INFO     10:36:31     Evaluating...\n",
      "INFO     10:36:33     [81: 157]: eps=0.031372549020 CE=0.9033 Err=0.2681 Loss=1.7849 Robust_CE=1.7849 Verified_Err=0.4446 Time=0.0031\n",
      "INFO     10:36:33     Epoch 82, learning rate [5e-05]\n",
      "INFO     10:36:35     [82:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.6787 Loss=0.0262 Robust_CE=0.0262 Time=0.0103\n",
      "INFO     10:36:35     [82: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.6599 Loss=0.0259 Robust_CE=0.0259 Time=0.0101\n",
      "INFO     10:36:36     [82: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.6582 Loss=0.0260 Robust_CE=0.0260 Time=0.0101\n",
      "INFO     10:36:36     [82: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.6600 Loss=0.0260 Robust_CE=0.0260 Time=0.0100\n",
      "INFO     10:36:36     Epoch time: 2.9995, Total time: 255.3015\n",
      "INFO     10:36:36     Evaluating...\n",
      "INFO     10:36:38     [82: 157]: eps=0.031372549020 CE=0.9014 Err=0.2679 Loss=1.7837 Robust_CE=1.7837 Verified_Err=0.4440 Time=0.0031\n",
      "INFO     10:36:38     Epoch 83, learning rate [5e-05]\n",
      "INFO     10:36:40     [83:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.6353 Loss=0.0242 Robust_CE=0.0242 Time=0.0103\n",
      "INFO     10:36:40     [83: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.6146 Loss=0.0244 Robust_CE=0.0244 Time=0.0102\n",
      "INFO     10:36:41     [83: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.6191 Loss=0.0247 Robust_CE=0.0247 Time=0.0101\n",
      "INFO     10:36:41     [83: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.6361 Loss=0.0247 Robust_CE=0.0247 Time=0.0101\n",
      "INFO     10:36:41     Epoch time: 3.0076, Total time: 258.3092\n",
      "INFO     10:36:41     Evaluating...\n",
      "INFO     10:36:43     [83: 157]: eps=0.031372549020 CE=0.9005 Err=0.2668 Loss=1.7835 Robust_CE=1.7835 Verified_Err=0.4441 Time=0.0031\n",
      "INFO     10:36:43     Epoch 84, learning rate [5e-05]\n",
      "INFO     10:36:45     [84:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.5980 Loss=0.0246 Robust_CE=0.0246 Time=0.0103\n",
      "INFO     10:36:45     [84: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.5849 Loss=0.0236 Robust_CE=0.0236 Time=0.0102\n",
      "INFO     10:36:46     [84: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.5824 Loss=0.0236 Robust_CE=0.0236 Time=0.0101\n",
      "INFO     10:36:46     [84: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.5872 Loss=0.0236 Robust_CE=0.0236 Time=0.0101\n",
      "INFO     10:36:46     Epoch time: 2.9952, Total time: 261.3044\n",
      "INFO     10:36:46     Evaluating...\n",
      "INFO     10:36:48     [84: 157]: eps=0.031372549020 CE=0.9000 Err=0.2678 Loss=1.7833 Robust_CE=1.7833 Verified_Err=0.4426 Time=0.0031\n",
      "INFO     10:36:48     Epoch 85, learning rate [5e-05]\n",
      "INFO     10:36:50     [85:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.5371 Loss=0.0220 Robust_CE=0.0220 Time=0.0104\n",
      "INFO     10:36:50     [85: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.5418 Loss=0.0224 Robust_CE=0.0224 Time=0.0102\n",
      "INFO     10:36:51     [85: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.5540 Loss=0.0226 Robust_CE=0.0226 Time=0.0102\n",
      "INFO     10:36:51     [85: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.5520 Loss=0.0225 Robust_CE=0.0225 Time=0.0101\n",
      "INFO     10:36:51     Epoch time: 2.9978, Total time: 264.3022\n",
      "INFO     10:36:51     Evaluating...\n",
      "INFO     10:36:53     [85: 157]: eps=0.031372549020 CE=0.9033 Err=0.2678 Loss=1.7891 Robust_CE=1.7891 Verified_Err=0.4440 Time=0.0031\n",
      "INFO     10:36:53     Epoch 86, learning rate [5e-06]\n",
      "INFO     10:36:55     [86:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.5079 Loss=0.0213 Robust_CE=0.0213 Time=0.0103\n",
      "INFO     10:36:55     [86: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4987 Loss=0.0213 Robust_CE=0.0213 Time=0.0101\n",
      "INFO     10:36:56     [86: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.5117 Loss=0.0214 Robust_CE=0.0214 Time=0.0101\n",
      "INFO     10:36:56     [86: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.5118 Loss=0.0214 Robust_CE=0.0214 Time=0.0100\n",
      "INFO     10:36:56     Epoch time: 2.9826, Total time: 267.2847\n",
      "INFO     10:36:56     Evaluating...\n",
      "INFO     10:36:58     [86: 157]: eps=0.031372549020 CE=0.9022 Err=0.2678 Loss=1.7878 Robust_CE=1.7878 Verified_Err=0.4435 Time=0.0031\n",
      "INFO     10:36:58     Epoch 87, learning rate [5e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:36:59     [87:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4927 Loss=0.0212 Robust_CE=0.0212 Time=0.0103\n",
      "INFO     10:37:00     [87: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.5119 Loss=0.0212 Robust_CE=0.0212 Time=0.0101\n",
      "INFO     10:37:00     [87: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.5028 Loss=0.0212 Robust_CE=0.0212 Time=0.0101\n",
      "INFO     10:37:01     [87: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.5088 Loss=0.0213 Robust_CE=0.0213 Time=0.0100\n",
      "INFO     10:37:01     Epoch time: 2.9763, Total time: 270.2610\n",
      "INFO     10:37:01     Evaluating...\n",
      "INFO     10:37:03     [87: 157]: eps=0.031372549020 CE=0.9015 Err=0.2673 Loss=1.7869 Robust_CE=1.7869 Verified_Err=0.4434 Time=0.0031\n",
      "INFO     10:37:03     Epoch 88, learning rate [5e-06]\n",
      "INFO     10:37:04     [88:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.5028 Loss=0.0213 Robust_CE=0.0213 Time=0.0103\n",
      "INFO     10:37:05     [88: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4961 Loss=0.0213 Robust_CE=0.0213 Time=0.0102\n",
      "INFO     10:37:05     [88: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.5032 Loss=0.0212 Robust_CE=0.0212 Time=0.0101\n",
      "INFO     10:37:06     [88: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.5041 Loss=0.0212 Robust_CE=0.0212 Time=0.0100\n",
      "INFO     10:37:06     Epoch time: 2.9824, Total time: 273.2435\n",
      "INFO     10:37:06     Evaluating...\n",
      "INFO     10:37:07     [88: 157]: eps=0.031372549020 CE=0.9012 Err=0.2673 Loss=1.7865 Robust_CE=1.7865 Verified_Err=0.4428 Time=0.0031\n",
      "INFO     10:37:07     Epoch 89, learning rate [5e-06]\n",
      "INFO     10:37:09     [89:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.5065 Loss=0.0210 Robust_CE=0.0210 Time=0.0103\n",
      "INFO     10:37:10     [89: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4899 Loss=0.0208 Robust_CE=0.0208 Time=0.0102\n",
      "INFO     10:37:10     [89: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.5052 Loss=0.0211 Robust_CE=0.0211 Time=0.0101\n",
      "INFO     10:37:10     [89: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.5154 Loss=0.0211 Robust_CE=0.0211 Time=0.0101\n",
      "INFO     10:37:10     Epoch time: 2.9872, Total time: 276.2306\n",
      "INFO     10:37:10     Evaluating...\n",
      "INFO     10:37:13     [89: 157]: eps=0.031372549020 CE=0.9009 Err=0.2669 Loss=1.7862 Robust_CE=1.7862 Verified_Err=0.4424 Time=0.0034\n",
      "INFO     10:37:13     Epoch 90, learning rate [5e-06]\n",
      "INFO     10:37:14     [90:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4805 Loss=0.0210 Robust_CE=0.0210 Time=0.0099\n",
      "INFO     10:37:15     [90: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4971 Loss=0.0211 Robust_CE=0.0211 Time=0.0102\n",
      "INFO     10:37:16     [90: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4871 Loss=0.0209 Robust_CE=0.0209 Time=0.0100\n",
      "INFO     10:37:16     [90: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4947 Loss=0.0210 Robust_CE=0.0210 Time=0.0099\n",
      "INFO     10:37:16     Epoch time: 3.3364, Total time: 279.5670\n",
      "INFO     10:37:16     Evaluating...\n",
      "INFO     10:37:18     [90: 157]: eps=0.031372549020 CE=0.9009 Err=0.2673 Loss=1.7862 Robust_CE=1.7862 Verified_Err=0.4426 Time=0.0049\n",
      "INFO     10:37:18     Epoch 91, learning rate [5e-06]\n",
      "INFO     10:37:20     [91:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4637 Loss=0.0199 Robust_CE=0.0199 Time=0.0125\n",
      "INFO     10:37:21     [91: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4711 Loss=0.0203 Robust_CE=0.0203 Time=0.0112\n",
      "INFO     10:37:21     [91: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4933 Loss=0.0208 Robust_CE=0.0208 Time=0.0106\n",
      "INFO     10:37:22     [91: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.5003 Loss=0.0209 Robust_CE=0.0209 Time=0.0107\n",
      "INFO     10:37:22     Epoch time: 3.4398, Total time: 283.0068\n",
      "INFO     10:37:22     Evaluating...\n",
      "INFO     10:37:24     [91: 157]: eps=0.031372549020 CE=0.9007 Err=0.2674 Loss=1.7862 Robust_CE=1.7862 Verified_Err=0.4423 Time=0.0037\n",
      "INFO     10:37:24     Epoch 92, learning rate [5e-06]\n",
      "INFO     10:37:26     [92:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4926 Loss=0.0206 Robust_CE=0.0206 Time=0.0101\n",
      "INFO     10:37:26     [92: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4901 Loss=0.0208 Robust_CE=0.0208 Time=0.0100\n",
      "INFO     10:37:27     [92: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4983 Loss=0.0209 Robust_CE=0.0209 Time=0.0099\n",
      "INFO     10:37:27     [92: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4988 Loss=0.0208 Robust_CE=0.0208 Time=0.0099\n",
      "INFO     10:37:27     Epoch time: 3.0524, Total time: 286.0592\n",
      "INFO     10:37:27     Evaluating...\n",
      "INFO     10:37:29     [92: 157]: eps=0.031372549020 CE=0.9007 Err=0.2681 Loss=1.7863 Robust_CE=1.7863 Verified_Err=0.4421 Time=0.0031\n",
      "INFO     10:37:29     Epoch 93, learning rate [5e-06]\n",
      "INFO     10:37:31     [93:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.5002 Loss=0.0203 Robust_CE=0.0203 Time=0.0102\n",
      "INFO     10:37:31     [93: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4953 Loss=0.0208 Robust_CE=0.0208 Time=0.0100\n",
      "INFO     10:37:32     [93: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4893 Loss=0.0207 Robust_CE=0.0207 Time=0.0100\n",
      "INFO     10:37:32     [93: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4903 Loss=0.0207 Robust_CE=0.0207 Time=0.0100\n",
      "INFO     10:37:32     Epoch time: 3.0192, Total time: 289.0783\n",
      "INFO     10:37:32     Evaluating...\n",
      "INFO     10:37:34     [93: 157]: eps=0.031372549020 CE=0.9006 Err=0.2681 Loss=1.7863 Robust_CE=1.7863 Verified_Err=0.4427 Time=0.0031\n",
      "INFO     10:37:34     Epoch 94, learning rate [5e-06]\n",
      "INFO     10:37:36     [94:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4792 Loss=0.0200 Robust_CE=0.0200 Time=0.0102\n",
      "INFO     10:37:36     [94: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4755 Loss=0.0202 Robust_CE=0.0202 Time=0.0101\n",
      "INFO     10:37:37     [94: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4877 Loss=0.0206 Robust_CE=0.0206 Time=0.0100\n",
      "INFO     10:37:37     [94: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4892 Loss=0.0206 Robust_CE=0.0206 Time=0.0100\n",
      "INFO     10:37:37     Epoch time: 2.9894, Total time: 292.0677\n",
      "INFO     10:37:37     Evaluating...\n",
      "INFO     10:37:39     [94: 157]: eps=0.031372549020 CE=0.9004 Err=0.2675 Loss=1.7862 Robust_CE=1.7862 Verified_Err=0.4424 Time=0.0031\n",
      "INFO     10:37:39     Epoch 95, learning rate [5e-06]\n",
      "INFO     10:37:41     [95:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4837 Loss=0.0209 Robust_CE=0.0209 Time=0.0102\n",
      "INFO     10:37:41     [95: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4684 Loss=0.0204 Robust_CE=0.0204 Time=0.0100\n",
      "INFO     10:37:42     [95: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4768 Loss=0.0204 Robust_CE=0.0204 Time=0.0100\n",
      "INFO     10:37:42     [95: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4806 Loss=0.0204 Robust_CE=0.0204 Time=0.0100\n",
      "INFO     10:37:42     Epoch time: 3.0042, Total time: 295.0719\n",
      "INFO     10:37:42     Evaluating...\n",
      "INFO     10:37:44     [95: 157]: eps=0.031372549020 CE=0.9002 Err=0.2679 Loss=1.7861 Robust_CE=1.7861 Verified_Err=0.4423 Time=0.0031\n",
      "INFO     10:37:44     Epoch 96, learning rate [5e-06]\n",
      "INFO     10:37:45     [96:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4701 Loss=0.0204 Robust_CE=0.0204 Time=0.0102\n",
      "INFO     10:37:46     [96: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4813 Loss=0.0206 Robust_CE=0.0206 Time=0.0101\n",
      "INFO     10:37:46     [96: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4796 Loss=0.0204 Robust_CE=0.0204 Time=0.0100\n",
      "INFO     10:37:47     [96: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4771 Loss=0.0203 Robust_CE=0.0203 Time=0.0099\n",
      "INFO     10:37:47     Epoch time: 2.9784, Total time: 298.0503\n",
      "INFO     10:37:47     Evaluating...\n",
      "INFO     10:37:49     [96: 157]: eps=0.031372549020 CE=0.9003 Err=0.2676 Loss=1.7864 Robust_CE=1.7864 Verified_Err=0.4422 Time=0.0031\n",
      "INFO     10:37:49     Epoch 97, learning rate [5e-06]\n",
      "INFO     10:37:50     [97:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4835 Loss=0.0203 Robust_CE=0.0203 Time=0.0102\n",
      "INFO     10:37:51     [97: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4708 Loss=0.0202 Robust_CE=0.0202 Time=0.0101\n",
      "INFO     10:37:51     [97: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4708 Loss=0.0201 Robust_CE=0.0201 Time=0.0100\n",
      "INFO     10:37:52     [97: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4715 Loss=0.0202 Robust_CE=0.0202 Time=0.0100\n",
      "INFO     10:37:52     Epoch time: 3.0001, Total time: 301.0503\n",
      "INFO     10:37:52     Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     10:37:54     [97: 157]: eps=0.031372549020 CE=0.9003 Err=0.2678 Loss=1.7865 Robust_CE=1.7865 Verified_Err=0.4422 Time=0.0031\n",
      "INFO     10:37:54     Epoch 98, learning rate [5e-06]\n",
      "INFO     10:37:55     [98:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4726 Loss=0.0202 Robust_CE=0.0202 Time=0.0103\n",
      "INFO     10:37:56     [98: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4718 Loss=0.0203 Robust_CE=0.0203 Time=0.0101\n",
      "INFO     10:37:56     [98: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4710 Loss=0.0202 Robust_CE=0.0202 Time=0.0101\n",
      "INFO     10:37:57     [98: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4724 Loss=0.0201 Robust_CE=0.0201 Time=0.0100\n",
      "INFO     10:37:57     Epoch time: 3.0236, Total time: 304.0739\n",
      "INFO     10:37:57     Evaluating...\n",
      "INFO     10:37:59     [98: 157]: eps=0.031372549020 CE=0.9004 Err=0.2682 Loss=1.7868 Robust_CE=1.7868 Verified_Err=0.4425 Time=0.0031\n",
      "INFO     10:37:59     Epoch 99, learning rate [5e-06]\n",
      "INFO     10:38:00     [99:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4243 Loss=0.0187 Robust_CE=0.0187 Time=0.0103\n",
      "INFO     10:38:01     [99: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4524 Loss=0.0194 Robust_CE=0.0194 Time=0.0101\n",
      "INFO     10:38:01     [99: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4726 Loss=0.0200 Robust_CE=0.0200 Time=0.0101\n",
      "INFO     10:38:02     [99: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4736 Loss=0.0200 Robust_CE=0.0200 Time=0.0100\n",
      "INFO     10:38:02     Epoch time: 3.0228, Total time: 307.0966\n",
      "INFO     10:38:02     Evaluating...\n",
      "INFO     10:38:04     [99: 157]: eps=0.031372549020 CE=0.9001 Err=0.2682 Loss=1.7867 Robust_CE=1.7867 Verified_Err=0.4423 Time=0.0031\n",
      "INFO     10:38:04     Epoch 100, learning rate [5e-06]\n",
      "INFO     10:38:06     [100:  50]: eps=0.031372549020 CE=0.0000 grad_norm=0.4427 Loss=0.0196 Robust_CE=0.0196 Time=0.0155\n",
      "INFO     10:38:07     [100: 100]: eps=0.031372549020 CE=0.0000 grad_norm=0.4713 Loss=0.0201 Robust_CE=0.0201 Time=0.0141\n",
      "INFO     10:38:07     [100: 150]: eps=0.031372549020 CE=0.0000 grad_norm=0.4622 Loss=0.0198 Robust_CE=0.0198 Time=0.0125\n",
      "INFO     10:38:08     [100: 157]: eps=0.031372549020 CE=0.0000 grad_norm=0.4637 Loss=0.0199 Robust_CE=0.0199 Time=0.0124\n",
      "INFO     10:38:08     Epoch time: 4.6486, Total time: 311.7452\n",
      "INFO     10:38:08     Evaluating...\n",
      "INFO     10:38:10     [100: 157]: eps=0.031372549020 CE=0.9001 Err=0.2678 Loss=1.7869 Robust_CE=1.7869 Verified_Err=0.4423 Time=0.0030\n"
     ]
    }
   ],
   "source": [
    "! python auto_LiRPA/examples/vision/purchase_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "914176d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4077\n",
      "Test accuracy: 0.2852\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "def get_acc(model, x, y):\n",
    "    _, predictions = torch.max(model(torch.from_numpy(x)), 1)\n",
    "    acc = np.mean(predictions.detach().numpy() == np.argmax(y, axis=1))\n",
    "    return acc\n",
    "\n",
    "model = purchase_model()\n",
    "model.load_state_dict(torch.load(\"models/purchase100_crown_ibp.pth\", map_location=torch.device('cpu'))['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "print(\"Train accuracy:\", get_acc(model, x_target_train, y_target_train))\n",
    "print(\"Test accuracy:\", get_acc(model, x_target_test, y_target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049c7c1",
   "metadata": {},
   "source": [
    "### 4. Generate Adversarial Examples using HopSkipJump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b921a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1842f21927044eeaa336202e43711a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HopSkipJump:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cab8d5af4464fcdbc886fb447adca77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HopSkipJump:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from art.attacks.evasion import HopSkipJump\n",
    "from art.estimators.classification.pytorch import PyTorchClassifier\n",
    "from numpy.random import choice\n",
    "\n",
    "art_classifier=PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=x_target_train[0].shape,\n",
    "    nb_classes=100,\n",
    ")\n",
    "attack = HopSkipJump(classifier=art_classifier, norm=2, targeted=False)\n",
    "\n",
    "train_idx = choice(len(x_target_train), 100)\n",
    "y_adv_train = y_target_train[train_idx]\n",
    "x_adv_train = attack.generate(x=x_target_train[train_idx], y=y_adv_train)\n",
    "\n",
    "test_idx = choice(len(x_target_test), 100)\n",
    "y_adv_test = y_target_test[test_idx]\n",
    "x_adv_test = attack.generate(x=x_target_test[test_idx], y=y_adv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64326b2",
   "metadata": {},
   "source": [
    "### 5. Measure the Distribution of Distance to Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e2a4898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "count  100.000000\n",
      "mean     0.463486\n",
      "std      0.399255\n",
      "min      0.007071\n",
      "25%      0.184963\n",
      "50%      0.379982\n",
      "75%      0.662314\n",
      "max      2.306716\n",
      "                0\n",
      "count  100.000000\n",
      "mean     0.442766\n",
      "std      0.432497\n",
      "min      0.000886\n",
      "25%      0.146327\n",
      "50%      0.322875\n",
      "75%      0.539153\n",
      "max      2.108539\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def dist(x, x_adv):\n",
    "    return np.linalg.norm(np.reshape(x_adv - x, [-1]))\n",
    "\n",
    "dist_train = [dist(x, xa) for (x, xa) in zip(x_target_train[train_idx], x_adv_train)]\n",
    "dist_test = [dist(x, xa) for (x, xa) in zip(x_target_test[test_idx], x_adv_test)]\n",
    "print(pd.DataFrame(np.array(dist_train)).describe())\n",
    "print(pd.DataFrame(np.array(dist_test)).describe())\n",
    "\n",
    "bins = [0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25]\n",
    "\n",
    "plt.hist(dist_train, bins, alpha=0.5, label='member')\n",
    "plt.hist(dist_test, bins, alpha=0.5, label='non-member')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(f\"{dataset} - {algorithm}\")\n",
    "plt.xlabel(\"Distance to Decision Boundary in L2 Norm\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba80423",
   "metadata": {},
   "source": [
    "### 6. Measure the Advantage of An Adversary in Label-Only Membership Inference Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed0254bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.   0.05 0.05 0.06 0.06 0.07 0.07 0.08 0.08 0.09 0.09 0.13 0.13\n",
      " 0.14 0.14 0.17 0.17 0.18 0.18 0.21 0.21 0.22 0.22 0.23 0.23 0.26 0.26\n",
      " 0.3  0.3  0.32 0.32 0.33 0.33 0.37 0.37 0.39 0.39 0.4  0.4  0.41 0.41\n",
      " 0.43 0.43 0.44 0.44 0.45 0.45 0.47 0.47 0.48 0.48 0.51 0.51 0.53 0.53\n",
      " 0.54 0.54 0.55 0.55 0.61 0.61 0.62 0.62 0.63 0.63 0.64 0.64 0.65 0.65\n",
      " 0.67 0.67 0.69 0.69 0.71 0.71 0.72 0.72 0.74 0.74 0.76 0.76 0.77 0.77\n",
      " 0.81 0.81 0.83 0.83 0.84 0.84 0.86 0.86 0.87 0.87 0.89 0.89 0.9  0.9\n",
      " 0.92 0.92 0.93 0.93 0.95 0.95 0.97 0.97 0.98 0.98 1.  ]\n",
      "[0.   0.01 0.01 0.05 0.05 0.06 0.06 0.07 0.07 0.11 0.11 0.12 0.12 0.14\n",
      " 0.14 0.19 0.19 0.23 0.23 0.27 0.27 0.31 0.31 0.32 0.32 0.33 0.33 0.34\n",
      " 0.34 0.35 0.35 0.36 0.36 0.39 0.39 0.41 0.41 0.44 0.44 0.45 0.45 0.49\n",
      " 0.49 0.51 0.51 0.52 0.52 0.53 0.53 0.54 0.54 0.55 0.55 0.56 0.56 0.57\n",
      " 0.57 0.58 0.58 0.59 0.59 0.62 0.62 0.64 0.64 0.65 0.65 0.66 0.66 0.67\n",
      " 0.67 0.73 0.73 0.75 0.75 0.76 0.76 0.77 0.77 0.79 0.79 0.8  0.8  0.81\n",
      " 0.81 0.82 0.82 0.83 0.83 0.85 0.85 0.87 0.87 0.88 0.88 0.89 0.89 0.9\n",
      " 0.9  0.93 0.93 0.94 0.94 0.97 0.97 0.98 0.98 1.   1.  ]\n",
      "[3.30671620e+00 2.30671620e+00 1.56031847e+00 1.35763264e+00\n",
      " 1.25917995e+00 1.21682847e+00 1.16494727e+00 1.10639656e+00\n",
      " 1.09526849e+00 1.02564836e+00 1.00340438e+00 9.35883403e-01\n",
      " 8.92141581e-01 8.33042502e-01 8.11085999e-01 7.48207629e-01\n",
      " 7.33880162e-01 6.90400839e-01 6.75477564e-01 6.46017432e-01\n",
      " 6.38097942e-01 5.91800988e-01 5.88162005e-01 5.83784044e-01\n",
      " 5.74940681e-01 5.57063699e-01 5.38578808e-01 5.23034751e-01\n",
      " 5.04413426e-01 5.03743589e-01 5.02914011e-01 4.99551296e-01\n",
      " 4.96871680e-01 4.85381812e-01 4.55714673e-01 4.41018283e-01\n",
      " 4.35706615e-01 4.20451403e-01 4.15648162e-01 4.14808005e-01\n",
      " 4.08571512e-01 3.91549110e-01 3.83583575e-01 3.79958361e-01\n",
      " 3.77315909e-01 3.76164585e-01 3.75088930e-01 3.60737383e-01\n",
      " 3.50204527e-01 3.48900914e-01 3.47705573e-01 3.46897960e-01\n",
      " 3.14686358e-01 3.12469304e-01 3.01828593e-01 2.92310983e-01\n",
      " 2.90888011e-01 2.90542513e-01 2.90473133e-01 2.83733040e-01\n",
      " 2.66942501e-01 2.57508725e-01 2.55948335e-01 2.51675934e-01\n",
      " 2.46486694e-01 2.44423136e-01 2.37689808e-01 2.35852256e-01\n",
      " 2.27187082e-01 2.22195700e-01 2.09793687e-01 1.93738624e-01\n",
      " 1.93520844e-01 1.86648428e-01 1.80973768e-01 1.79904997e-01\n",
      " 1.79744944e-01 1.79509476e-01 1.64905027e-01 1.50940254e-01\n",
      " 1.34068966e-01 1.34011403e-01 1.28423378e-01 1.26645580e-01\n",
      " 1.17543131e-01 1.14072971e-01 1.09228469e-01 1.05362855e-01\n",
      " 1.03405774e-01 9.95852202e-02 9.51129496e-02 8.96789506e-02\n",
      " 8.94272849e-02 8.65928382e-02 8.51702094e-02 7.49174729e-02\n",
      " 6.31813630e-02 6.24953955e-02 5.54053523e-02 5.24672419e-02\n",
      " 5.02398871e-02 5.01852743e-02 4.34861928e-02 4.13461477e-02\n",
      " 3.62856872e-02 2.98195090e-02 2.76162606e-02 7.07134278e-03\n",
      " 8.86303373e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(\n",
    "    np.concatenate((np.ones(len(dist_train)), np.zeros(len(dist_test)))),\n",
    "    dist_train + dist_test\n",
    ")\n",
    "print(fpr)\n",
    "print(tpr)\n",
    "print(thresholds)\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    np.concatenate((np.ones(len(dist_train)), np.zeros(len(dist_test)))),\n",
    "    dist_train + dist_test\n",
    ")\n",
    "plt.title(f\"{dataset} - {algorithm}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fb99d",
   "metadata": {},
   "source": [
    "### 7. Measure the Statistical Relationship between Distance to Decision Boundary and Confidence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b331301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train correlation  0.35194888399988566 0.00032960987515535283\n",
      "test correlation  0.2594928191765802 0.009130616285928192\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "import scipy\n",
    "\n",
    "confidence_train = [np.amax(scipy.special.softmax(p)) for p in art_classifier.predict(x_target_train[train_idx])]\n",
    "confidence_test = [np.amax(scipy.special.softmax(p)) for p in art_classifier.predict(x_target_test[test_idx])]\n",
    "\n",
    "corr, pvalue = pearsonr(confidence_train, dist_train)\n",
    "print(\"train correlation \", corr, pvalue)\n",
    "corr, pvalue = pearsonr(confidence_test, dist_test)\n",
    "print(\"test correlation \", corr, pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
